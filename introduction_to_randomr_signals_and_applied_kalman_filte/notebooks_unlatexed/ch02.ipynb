{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only really careful way to describe noise is to begin with a\n",
    "probabilistic description and then proceed to derive the associated spectral char-\n",
    "acteristics from the probabilistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time will usually be the independent variable, although this does not\n",
    "necessarily need to be the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A signal is said to be deterministic if it is exactly\n",
    "predictable for the time span of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are\n",
    "described by functions in the usual mathematical sense;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast with a deterministic signal, a random signal always has some\n",
    "element of chance associated with it. Thus, it is not predictable in a deterministic\n",
    "sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signals such as (d), (e), and (f) are formally known as random or\n",
    "stochastic processes, and we will use the terms random and stochastic interchange-\n",
    "ably throughout the remainder of the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\n",
    "might expect such a signal to have some kind of spectral description, because the\n",
    "signal is audible to the human ear. Yet the precise mathematical description of such\n",
    "a signal is remarkably elusive, and it eluded investigators prior to the 1940s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with random variables we\n",
    "must be able to visualize a conceptual statistical experiment in which samples of\n",
    "the random variable are obtained under identical chance circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would not\n",
    "be proper in this case to sample X by taking successive time samples of the same\n",
    "signal, because, if they were taken very close together, there would be a close\n",
    "statistical connection among nearby samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the conceptual experiment\n",
    "in this case must consist of many “identical” radios, all playing simultaneously, all\n",
    "being tuned away from regular stations in different portions of the broadcast band,\n",
    "and all having their volumes turned up to the same sound level.\n",
    "This then leads to the\n",
    "notion of an ensemble of similar noiselike signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen then that a random process is a set of random variables that\n",
    "unfold with time in accordance with some conceptual chance experiment. Each of\n",
    "the noiselike time signals so generated is called a sample realization of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radio experiment just described is an example of a continuous-time\n",
    "random process in that time evolves in a continuous manner. In this example,\n",
    "the probability density function describing the amplitude variation also happens to\n",
    "be continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\n",
    "One way to specify a random process is to\n",
    "describe in detail the conceptual chance experiment giving rise to the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, more information\n",
    "than just mean and variance is needed to completely describe a random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the first-order probability density functions f X 1 ðxÞ; f X 2 ðxÞ; . . . ; f X k ðxÞ,\n",
    "are important in describing the process because they tell us something about the\n",
    "process amplitude distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "the first-order densities tell us something about the relative distribution of the\n",
    "process amplitude as well as its mean and mean-square value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clear that the joint densities relating any pair of random variables,\n",
    "for example, f X 1 X 2 ðx 1 ; x 2 Þ; f X 1 X 3 ðx 1 ; x 3 Þ, and so forth, are also important in our\n",
    "process description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is these density functions that tell us something about how\n",
    "rapidly the signal changes with time, and these will eventually tell us something\n",
    "about the signal’s spectral content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing on, the third, fourth, and subsequent\n",
    "higher-order density functions provide even more detailed information about the\n",
    "process in probabilistic terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this leads to a formidable description of\n",
    "the process, to say the least, because a k-variate density function is required where k\n",
    "can be any positive integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from probability theory that two random variables X and Y are said to be\n",
    "statistically independent if their joint density function can be written in product\n",
    "form\n",
    "f XY ðx; yÞ 1⁄4 f X ðxÞf Y ðyÞ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, random processes X(t) and Y(t) are statistically independent if the joint\n",
    "density for any combination of random variables of the two processes can be written\n",
    "in product form, that is, X(t) and Y(t) are independent if\n",
    "f X 1 X 2 ...Y 1 Y 2 ... 1⁄4 f X 1 X 2 ... f Y 1 Y 2 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sample times do not have to be the same\n",
    "for the two processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3\n",
    "It is defined as one in which all the density functions\n",
    "describing the process are normal in form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is not sufficient that just\n",
    "the “amplitude” of the process be normally distributed; all higher-order density\n",
    "functions must also be normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multivariate normal density function was discussed in Section 1.14. It\n",
    "was pointed out there that matrix notation makes it possible to write out all k-\n",
    "variate density functions in the same compact matrix form, regardless of the size\n",
    "of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have to do is specify the vector random-variable mean and covariance\n",
    "matrix, and the density function is specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of a Gaussian random\n",
    "process the “variates” are the random variables X(t 1 ), X(t 2 ), . . . , X(t k ), where the\n",
    "points in time may be chosen arbitrarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, enough information must\n",
    "be supplied to specify the mean and covariance matrix regardless of the choice\n",
    "of t 1 , t 2 , . . . , t k ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4\n",
    "A random process is said to be time stationary or simply stationary if the density\n",
    "functions describing the process are invariant under a translation of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this applies to all the higher-\n",
    "order density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjective strict is also used occasionally with this\n",
    "type of stationarity to distinguish it from wide-sense stationarity, which is a less\n",
    "restrictive form of stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random process is said to be ergodic if time averaging is equivalent to\n",
    "ensemble averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a qualitative sense this implies that a single sample time\n",
    "signal of the process contains all possible statistical variations of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus,\n",
    "no additional information is to be gained by observing an ensemble of sample\n",
    "signals over the information obtained from a one-sample signal, for example, one\n",
    "long data recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, time and ensemble sampling do not lead to\n",
    "the same result in this case, so the process is not ergodic. It is, however, a stationary\n",
    "process because the “statistics” of the process do not change with time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of physical noise processes, one can rarely justify strict stationarity\n",
    "or ergodicity in a formal sense. Thus, we often lean on heuristic knowledge of the\n",
    "processes involved and simply make assumptions accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random processes are sometimes classified according to two categories,\n",
    "deterministic and nondeterministic. As might be expected, a deterministic random\n",
    "process resembles a deterministic nonrandom signal in that it has some special\n",
    "deterministic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, if the process description is such that knowl-\n",
    "edge of a sample signal’s past enables exact prediction of its future, it is classified as\n",
    "a deterministic random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random processes that are not deterministic are classified as nondetermin-\n",
    "istic. These processes have no special functional structure that enables their\n",
    "exact prediction by specification of certain key parameters or their past history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical “noise” is a good example of a nondeterministic random process. It\n",
    "wanders on aimlessly, as determined by chance, and has no particular determi-\n",
    "nistic structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5\n",
    "The autocorrelation function for a random process X(t) is defined as *\n",
    "R X ðt 1 ; t 2 Þ 1⁄4 E1⁄2Xðt 1 ÞXðt 2 Þ\u0005\n",
    "(2.5.1)\n",
    "where t 1 and t 2 are arbitrary sampling times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, it tells how well the process is\n",
    "correlated with itself at two different times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the process is stationary, its\n",
    "probability density functions are invariant with time, and the autocorrelation\n",
    "function depends only on the time difference t 2 \u0003 t 1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity assures us that the\n",
    "expectation is not dependent on t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the autocorrelation function is the ensemble average (i.e., expect-\n",
    "ation) of the product of X(t 1 ) and X(t 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,\n",
    "Eq. (2.5.3) is often not the simplest way of determining R X because the joint density\n",
    "function f X 1 X 2 ðx 1 ; x 2 Þ must be known explicitly in order to evaluate the integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If\n",
    "the ergodic hypothesis applies, it is often easier to compute R X as a time average\n",
    "rather than an ensemble average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for\n",
    "stationary ergodic processes, the direction of time shift t is immaterial, and hence\n",
    "the autocorrelation function is symmetric about the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the random process under consideration is not ergodic, and it is\n",
    "necessary to distinguish between the usual autocorrelation function (ensemble\n",
    "average) and the time-average version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we define the time autocorrelation\n",
    "function as ...\n",
    "where X A (t) denotes a sample realization of the X(t) process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some general properties that are common to all autocorrelation functions\n",
    "for stationary processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the\n",
    "magnitude of the correlation coefficient relating two random variables is\n",
    "never greater than unity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of interest to note that if the\n",
    "process is ergodic as well as stationary and if the periodic component\n",
    "is sinusoidal, then R X (t) will contain no information about the phase of\n",
    "the sinusoidal component. The harmonic component always appears\n",
    "in the autocorrelation function as a cosine function, irrespective of\n",
    "its phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was mentioned previously that strict stationarity is a severe requirement,\n",
    "because it requires that all the higher-order probability density functions be\n",
    "invariant under a time translation. This is often difficult to verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a less\n",
    "demanding form of stationarity is often used, or assumed. A random process is said\n",
    "to be covariance stationary or wide-sense stationary if E[X(t 1 )] is independent of t 1\n",
    "and E[X(t 1 )X(t 2 )] is dependent only on the time difference t 2 \u0003 t 1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, if the\n",
    "second-order density f X 1 X 2 ðx 1 ; x 2 Þ is independent of the time origin, the process is\n",
    "covariance stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the autocorrelation function is an important descriptor\n",
    "of a random process and one that is relatively easy to obtain because it depends on\n",
    "only the second-order probability density for the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6\n",
    "The crosscorrelation function between the processes X(t) and Y(t) is defined as ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if the processes are stationary, only the time difference between sample\n",
    "points is relevant, so the crosscorrelation function reduces to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as the autocorrelation function tells us something about how a process is\n",
    "correlated with itself, the crosscorrelation function provides information about the\n",
    "mutual correlation between the two processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A skew-symmetric relation exists for stationary processes as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, interchanging the order of the subscripts of the crosscorrelation function has\n",
    "the effect of changing the sign of the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We frequently need to consider additive combinations of random processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation function of the summed process is then ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7\n",
    "Qualitatively, if the autocorrelation function\n",
    "decreases rapidly with t, the process changes rapidly with time; conversely, a\n",
    "slowly changing process will have an autocorrelation function that decreases slowly\n",
    "with t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stationary\n",
    "processes, there is an important relation known as the Wiener–Khinchine relation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "power spectral density function or simply\n",
    "the spectral density function of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjectives power and spectral come from the relationship of S X ( jv) to the\n",
    "usual spectrum concept for a deterministic signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the process X(t) is time stationary, it wanders on ad\n",
    "infinitum and is not absolutely integrable. Thus, the defining integral for the Fourier\n",
    "transform does not converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any particular sample realization of X T (t), the quantity inside the brackets is\n",
    "known as the periodogram for that particular signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will now be shown that\n",
    "averaging over an ensemble of periodograms for large T yields the power spectral\n",
    "density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factor 1 \u0003 jtj=T that multiplies R X (t) may be thought of as a triangular\n",
    "weighting factor that approaches unity as T becomes large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (2.7.9) is a most important relationship, because it is this that ties the\n",
    "spectral function S X (jv) to “spectrum” as thought of in the usual deterministic sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the spectral density function, as formally defined by Eq. (2.7.1), is a\n",
    "probabilistic concept. On the other hand, the periodogram is a spectral concept\n",
    "in the usual sense of being related to the Fourier transform of a time signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The\n",
    "relationship given by Eq. (2.7.9) then provides the tie between the probabilistic and\n",
    "spectral descriptions of the process, and it is this equation that suggests the name for\n",
    "S X (jv), power spectral density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the determination of the spectral function from experimental data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, it is convenient to write the spectral density function in terms\n",
    "of the complex frequency variable s rather than v. This is done by simply replacing\n",
    "jv with s; or, equivalently, replacing v 2 with \u0003s 2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Fourier transform theory, we know that the inverse transform of the\n",
    "spectral function should yield the autocorrelation function, that is, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (2.7.16) provides a convenient means of computing the mean square value\n",
    "of a stationary process, given its spectral function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we see that the autocorrelation function and power spectral\n",
    "density function are Fourier transform pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, both contain the same basic\n",
    "information about the process, but in different forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can easily transform\n",
    "back and forth between the time and frequency domains, the manner in which the\n",
    "information is presented is purely a matter of convenience for the problem at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before leaving the subject of power spectral density, it is worthy of mention\n",
    "that when two processes x and y are uncorrelated, the spectral density of the sum is\n",
    "given by ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8\n",
    "White noise is defined to be a stationary random process having a constant spectral\n",
    "density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding autocorrelation function for white noise is then ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,\n",
    "by assuming the spectral amplitude of white noise to be constant for all frequencies\n",
    "(for the sake of mathematical simplicity), we find ourselves in the awkward\n",
    "situation of having defined a process with infinite variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, white\n",
    "noise is sometimes characterized as noise that is jumping around infinitely far, infinitely fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously physical nonsense but it is a useful abstraction. The\n",
    "saving feature is that all physical systems are bandlimited to some extent, and a\n",
    "bandlimited system driven by white noise yields a process that has finite variance;\n",
    "that is, the end result makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandlimited white noise is a random process whose spectral amplitude is\n",
    "constant over a finite range of frequencies, and zero outside that range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of interest to note that the autocorrelation\n",
    "function for baseband bandlimited white noise is zero for t 1⁄4 1=2W, 2=2W, 3=2W,\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that if the process is sampled at a rate of 2W samples/second\n",
    "(sometimes called the Nyquist rate), the resulting set of random variables are\n",
    "uncorrelated. Since this usually simplifies the analysis, the white bandlimited\n",
    "assumption is frequently made in bandlimited situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he frequency band for bandlimited white noise is sometimes offset from the\n",
    "origin and centered about some center frequency W 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting the bandlimited white noise has a finite mean-square value,\n",
    "and thus it is physically plausible, whereas pure white noise is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the\n",
    "mathematical forms for the autocorrelation and spectral functions in the band-\n",
    "limited case are more complicated than for pure white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before leaving the subject of white noise, it is worth mentioning that the\n",
    "analogous discrete-time process is referred to as a white sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A white sequence\n",
    "is defined simply as a sequence of zero-mean, uncorrelated random variables.\n",
    "That is, all members of the sequence have zero means and are mutually uncorrelated\n",
    "with all other members of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the random variables are also normal,\n",
    "then the sequence is a Gaussian white sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9\n",
    "A stationary Gaussian process X(t) that has an exponential autocorrelation is called\n",
    "a Gauss–Markov process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation and spectral functions for this process are then of the form .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean-square value and time\n",
    "constant for the process are given by the s 2 and 1=b parameters, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The\n",
    "process is nondeterministic, so a typical sample time function would show no\n",
    "deterministic structure and would look like typical “noise.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exponential\n",
    "autocorrelation function indicates that sample values of the process gradually\n",
    "become less and less correlated as the time separation between samples increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation function approaches zero as t ! 1, and thus the mean value\n",
    "of the process must be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gauss–Markov process is an important process in applied work because\n",
    "(1) it seems to fit a large number of physical processes with reasonable accuracy,\n",
    "and (2) it has a relatively simple mathematical description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of all\n",
    "stationary Gaussian processes, specification of the process autocorrelation function\n",
    "completely defines the process. This means that any desired higher-order probability\n",
    "density function for the process may be written out explicitly, given the auto-\n",
    "correlation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that C X has been written out explicitly, we can use the general normal form\n",
    "given by Eq. (1.14.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple scalar Gauss–Markov process whose autocorrelation function is\n",
    "exponential is sometimes referred to as a first-order Gauss–Markov process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is\n",
    "because the discrete-time version of the process is described by a first-order\n",
    "difference equation of the form .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where W(t k ) is an uncorrelated zero-mean Gaussian sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete-time\n",
    "Gaussian processes that satisfy higher-order difference equations are also often\n",
    "referred to as Gauss–Markov processes of the appropriate order. Such processes are\n",
    "best described in vector form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.10\n",
    "In both control and communication systems, we frequently encounter situations\n",
    "where a very narrowband system is excited by wideband Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high-Q\n",
    "tuned circuit and/or a lightly damped mass–spring arrangement are examples of\n",
    "narrowband systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output is a noise process with essentially all its\n",
    "spectral content concentrated in a narrow frequency range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one were to observe\n",
    "the output of such a system, the time function would appear to be nearly sinusoidal,\n",
    "especially if just a few cycles of the output signal were observed. However, if one\n",
    "were to carefully examine a long record of the signal, it would be seen that the quasi-\n",
    "sinusoid is slowly varying in both amplitude and phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a signal is called\n",
    "narrowband noise and, if it is the result of passing wideband Gaussian noise through\n",
    "a linear narrowband system, then it is also Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quasi-sinusoidal character depends only on the narrowband property,\n",
    "and the exact spectral shape within the band is immaterial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical description of narrowband Gaussian noise follows. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where X(t) and Y(t) are independent Gaussian random processes with similar\n",
    "narrowband spectral functions that are centered about zero frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fre-\n",
    "quency v c is usually called the carrier frequency, and the effect of multiplying X(t)\n",
    "and Y(t) by cos v c t and sin v c t is to translate the baseband spectrum up to a similar\n",
    "spectrum centered about v c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent X(t) and Y(t)\n",
    "processes are frequently called the in-phase and quadrature components of S(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If X and Y are independent normal random variables with the same\n",
    "variance s 2 , their individual and joint densities are ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding densities for R and Q are Rayleigh and uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of interest to note here that if we consider simultaneous time samples of\n",
    "envelope and phase, the resulting random variables are statistically independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the processes R(t) and Q(t) are not statistically independent (5). This is\n",
    "due to the fact that the joint probability density associated with adjacent samples\n",
    "cannot be written in product form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher-order density functions for S will, of course, depend on the specific\n",
    "shape of the spectral density for the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we start at the origin and take n steps forward or backward at random,\n",
    "with equal likelihood of stepping in either direction. We pose two questions:\n",
    "After taking n steps, (1) what is the average distance traveled, and (2) what is the\n",
    "variance of the distance? This is the classical random-walk problem of statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The averages considered here must be taken in an ensemble sense; for example,\n",
    "think of running simultaneous experiments and then averaging the results for a\n",
    "given number of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is shown in elementary statistics\n",
    "p ffiffiffi that\n",
    "the variance after n unit steps is just n, or the standard deviation is n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous analog of random-walk is the output of an integrator driven\n",
    "with white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add the further requirement that the input be Gaussian white noise. The\n",
    "output will then be a Gaussian process because integration is a linear operation on\n",
    "the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he resulting continuous random-walk process is known as the Wiener or\n",
    "Brownian-motion process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is nonstationary, it is Gaussian, and its\n",
    "mean, mean-square value, and autocorrelation function are given by ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the process is nonstationary, the autocorrelation function is a general function\n",
    "of the two arguments t 1 and t 2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was mentioned before that there are difficulties in defining directly what is\n",
    "meant by Gaussian white noise. This is because of the “infinite variance” problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wiener process is well behaved, though. Thus, we can reverse the argument\n",
    "given here and begin by arbitrarily defining it as a Gaussian process with an\n",
    "autocorrelation function given by Eq. (2.11.7). This completely specifies the\n",
    "process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now describe Gaussian white noise in terms of its integral.\n",
    "That is, Gaussian white noise is that hypothetical process which, when integrated,\n",
    "yields a Wiener process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.12\n",
    "As the name implies, pseudorandom signals have the appearance of being random,\n",
    "but are not truly random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a signal to be truly random, there must be\n",
    "some uncertainty about it that is governed by chance. Pseudorandom signals do\n",
    "not have this “chance” property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudorandom noise of the type just described would not be of much value in\n",
    "today’s digital world. Yet, computer-generated pseudorandom noise has proved\n",
    "quite useful in a variety of practical applications,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.13\n",
    "pectral determination is a\n",
    "relatively complicated problem with many pitfalls, and one should approach it\n",
    "with a good deal of caution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is closely related to the larger problem of digital data\n",
    "processing, because the amount of data needed is usually large, and processing it\n",
    "either manually or in analog form is often not feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first consider the span of\n",
    "observation time of the experimental data, which is a fundamental limitation,\n",
    "irrespective of the means of processing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time span of the data to be analyzed must, of course, be finite; and, as a\n",
    "practical matter, we prefer not to analyze any more data than is necessary to achieve\n",
    "reasonable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that since this is a matter of statistical inference, there\n",
    "will always remain some statistical uncertainty in the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to specify the\n",
    "accuracy of the experimentally determined spectrum or autocorrelation function is\n",
    "to say that its variance must be less than a specified value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General accuracy bounds\n",
    "applicable to all processes are not available but there is one special case, the\n",
    "Gaussian process, that is amenable to analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not give the proof here, but it\n",
    "can be shown (11) that the variance of an experimentally determined auto-\n",
    "correlation function satisfies the inequality ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be mentioned that in determining the time average of X T (t)X T (t þ t), we\n",
    "cannot use the whole span of time T, because X T (t) must be shifted an amount of t\n",
    "with respect to itself before multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true extension of X T (t) beyond the\n",
    "experimental data span is unknown; therefore, we simply omit the nonoverlapped\n",
    "portion in the integration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first note that V X (t) is the result of analyzing a single time signal;\n",
    "therefore, V X (t) is itself just a sample function from an ensemble of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is\n",
    "hoped that V X (t) as determined by Eq. (2.13.2) will yield a good estimate of R X (t)\n",
    "and, in order to do so, it should be an unbiased estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (2.13.1) is of little value if the process autocorrelation function is not\n",
    "known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, at this point, we assume that X(t) is a Gauss–Markov process with an\n",
    "autocorrelation function ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The s 2 and b parameters may be difficult to determine in a real-life problem, but we\n",
    "can get at least a rough estimate of the amount of experimental data needed for a\n",
    "given required accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 10 percent accuracy is really not an especially\n",
    "demanding requirement, but yet the data required is 200 times the time constant of\n",
    "the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that accurate determination of the autocorrelation\n",
    "function is not a trivial problem in some applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main point to be learned from this example is that reliable determination of\n",
    "the autocorrelation function takes considerably more experimental data than one\n",
    "might expect intuitively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectral density function is just the Fourier transform\n",
    "of the autocorrelation function, so we might expect a similar accuracy problem in its\n",
    "experimental determination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As just mentioned, the spectral density function for a given sample signal may\n",
    "be estimated by taking the Fourier transform of the experimentally determined\n",
    "autocorrelation function. This, of course, involves a numerical procedure of some\n",
    "sort because the data describing V X (t) will be in numerical form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectral\n",
    "function may also be estimated directly from the periodogram of the sample signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, since we do not usually have the luxury of having a large\n",
    "ensemble of periodograms to average, there are pitfalls in this approach, just as there\n",
    "are in going the autocorrelation route."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, modern digital processing\n",
    "methods using fast Fourier transform (FFT) techniques have popularized the\n",
    "periodogram approach. Thus, it is important to understand its limitations (6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, there is the truncation problem. When the time record being analyzed is\n",
    "finite in length, we usually assume that the signal will “jump” abruptly to zero\n",
    "outside the valid data interval. This causes frequency spreading and gives rise to\n",
    "high-frequency components that are not truly representative of the process under\n",
    "consideration, which is assumed to ramble on indefinitely in a continuous manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the first rule is that we must\n",
    "have a long time record relative to the typical time variations in the signal. This is\n",
    "true regardless of the method used in analyzing the data. There is, however, a\n",
    "statistical convergence problem that arises as the record length becomes large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Section 2.7 it was shown that the expectation of the periodogram approaches\n",
    "the spectral density of the process for large T. This is certainly desirable, because we\n",
    "want the periodogram to be an unbiased estimate of the spectral density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also of\n",
    "interest to look at the behavior of the variance of the periodogram as T becomes\n",
    "large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But E(M) approaches the spectral function as T ! 1. Thus, the variance of the\n",
    "periodogram does not go to zero as T ! 1 (except possibly at those exceptional\n",
    "points where the spectral function is zero). In other words, the periodogram does not\n",
    "converge in the mean as T ! 1! This is most disturbing, especially in view of the\n",
    "popularity of the periodogram method of spectral determination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing T will not help reduce the ripples in the\n",
    "individual periodogram. It simply makes M “jump around” faster with v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our treatment of the general problem of autocorrelation and spectral determi-\n",
    "nation from experimental data must be brief. However, the message here should be\n",
    "clear. Treat this problem with respect. It is fraught with subtleties and pitfalls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineering literature abounds with reports of shoddy spectral analysis methods\n",
    "and the attendant questionable results. Know your digital signal processing methods\n",
    "and recognize the limitations of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.14\n",
    "Consider a time function g(t) that is bandlimited,\n",
    "Under the conditions of Eq. (2.14.1), the time function can be written in the form ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theorem says that if one\n",
    "were to specify an infinite sequence of sample values . . . , g 1 , g 2 , g 3 , . . . , uniformly\n",
    "spaced 1/2W sec apart as shown in Fig. 2.27, then there would be one and only one\n",
    "bandlimited function that would go through all the sample values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words,\n",
    "specifying the signal sample values and requiring g(t) to be bandlimited indirectly\n",
    "specify the signal in between the sample points as well. The sampling rate of 2W Hz is\n",
    "known as the Nyquist rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the minimum sampling rate needed to\n",
    "preserve all the information content in the continuous signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sample g(t) at less\n",
    "than the Nyquist rate, some information will be lost, and the original signal cannot be\n",
    "exactly reconstructed on the basis of the sequence of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly, a signal\n",
    "lying within the bandwidth W also lies within a bandwidth greater than W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In describing a stationary random process that is bandlimited, it can be seen\n",
    "that we need to consider only the statistical properties of samples taken at the\n",
    "Nyquist rate of 2W Hz. This simplifies the process description considerably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If\n",
    "we add the further requirement that the process is Gaussian and white within the\n",
    "bandwidth W, then the joint probability density for the samples may be written as a\n",
    "simple product of single-variate normal density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is symmetry in the direct and inverse Fourier transforms, we would\n",
    "expect there to be a corresponding sampling theorem in the frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the previous comments relative to time domain sampling have their\n",
    "corresponding frequency-domain counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
