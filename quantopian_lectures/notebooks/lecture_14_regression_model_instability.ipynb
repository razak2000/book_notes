{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Regression analysis allows us to estimate coefficients in a function which approximately relates multiple data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We hypothesize a specific form for this function and then find coefficients which fit the data well, working under the assumption that deviations from the model can be considered noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>When building such a model, we accept that it cannot perfectly predict the dependent variable. Here we would like to evaluate the accuracy of the model not by how well it explains the dependent variable, but by how stable it is (that is, how stable the regression coefficients are) with respect to our sample data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After all, if a model is truly a good fit, it should be similar, say, for two random halves of our data set that we model individually. Otherwise, we cannot assume that the model isn't simply an artifact of the particular sample of data we happened to choose, or that it will be predictive of new data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using linear regressions here for illustration purposes, but the same considerations apply for all regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels import regression, stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X,Y):\n",
    "    # Running the linear regression\n",
    "    x = sm.add_constant(X) # Add a row of 1's so that our model has a constant term\n",
    "    model = regression.linear_model.OLS(Y, x).fit()\n",
    "    return model.params[0], model.params[1] # Return the coefficients of the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The particular sample we choose for the data affects the model generated, and unevenly distributed noise can lead to an inaccurate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're drawing from a normal distribution, but <font color='blue'>because we do not have very many data points, we get a significant downward bias. If we took more measurements, both of the regression coefficients would move toward zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw observations from normal distribution\n",
    "np.random.seed(107) # Fix seed for random number generation\n",
    "rand = np.random.randn(20)\n",
    "# Conduct linear regression on the ordered list of observations\n",
    "xs = np.arange(20)\n",
    "a, b = linreg(xs, rand)\n",
    "print 'Slope:', b, 'Intercept:', a\n",
    "# Plot the raw data and the regression line\n",
    "plt.scatter(xs, rand, alpha=0.7)\n",
    "Y_hat = xs * b + a\n",
    "plt.plot(xs, Y_hat, 'r', alpha=0.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.regplot(xs, rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Regression analysis is very sensitive to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes these outliers contain information, in which case we want to take them into account; however, in cases like the above, they can simply be random noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A regime change (or structural break) is when something changes in the process generating the data, causing future samples to follow a different distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below,<font color='blue'> we can see that there is a regime change at the end of 2007, and splitting the data there results in a much better fit (in red) than a regression on the whole data set (yellow). \n",
    "\n",
    "In this case our regression model will not be predictive of future data points since the underlying system is no longer the same as in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>In fact, the regression analysis assumes that the errors are uncorrelated and have constant variance, which is often not be the case if there is a regime change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Of course, the more pieces we break our data set into, the more precisely we can fit to it. It's important to avoid fitting to noise, which will always fluctuate and is not predictive. \n",
    "\n",
    "<font color='blue'>We can test for the existence of a structural break, either at a particular point we have identified or in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use a test from statsmodels which computes the probability of observing the data if there were no breakpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.diagnostic.breaks_cusumolsresid(\n",
    "    regression.linear_model.OLS(pricing, sm.add_constant(xs)).fit().resid)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Above we were only considering regressions of one dependent variable against one independent one. However, we can also have multiple independent variables. This leads to instability if the independent variables are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we are using two independent variables, $X_1$ and $X_2$, which are very highly correlated. Then the coefficients may shift drastically if we add a new observation that is slightly better explained by one of the two than by the other. In the extreme case, if $X_1 = X_2$, then the choice of coefficients will depend on the particular linear regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run a multiple linear regression in which the independent variables are highly correlated. If we take our sample period to be 2013-01-01 to 2015-01-01, then the coefficients are approximately .25 and .1. But if we extend the period to 2015-06-01, the coefficients become approximately .18 and .20, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pricing data for two benchmarks (stock indices) and a stock\n",
    "start = '2013-01-01'\n",
    "end = '2015-01-01'\n",
    "b1 = get_pricing('SPY', fields='price', start_date=start, end_date=end)\n",
    "b2 = get_pricing('MDY', fields='price', start_date=start, end_date=end)\n",
    "asset = get_pricing('V', fields='price', start_date=start, end_date=end)\n",
    "mlr = regression.linear_model.OLS(asset, sm.add_constant(np.column_stack((b1, b2)))).fit()\n",
    "prediction = mlr.params[0] + mlr.params[1]*b1 + mlr.params[2]*b2\n",
    "print 'Constant:', mlr.params[0], 'MLR beta to S&P 500:', mlr.params[1], ' MLR beta to MDY', mlr.params[2]\n",
    "# Plot the asset pricing data and the regression model prediction, just for fun\n",
    "asset.plot()\n",
    "prediction.plot();\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['Asset', 'Linear Regression Prediction']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pricing data for two benchmarks (stock indices) and a stock\n",
    "start = '2013-01-01'\n",
    "end = '2015-06-01'\n",
    "b1 = get_pricing('SPY', fields='price', start_date=start, end_date=end)\n",
    "b2 = get_pricing('MDY', fields='price', start_date=start, end_date=end)\n",
    "asset = get_pricing('V', fields='price', start_date=start, end_date=end)\n",
    "mlr = regression.linear_model.OLS(asset, sm.add_constant(np.column_stack((b1, b2)))).fit()\n",
    "prediction = mlr.params[0] + mlr.params[1]*b1 + mlr.params[2]*b2\n",
    "print 'Constant:', mlr.params[0], 'MLR beta to S&P 500:', mlr.params[1], ' MLR beta to MDY', mlr.params[2]\n",
    "# Plot the asset pricing data and the regression model prediction, just for fun\n",
    "asset.plot()\n",
    "prediction.plot();\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['Asset', 'Linear Regression Prediction']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We can check that our independent variables are correlated by computing their correlation coefficient. This number always lies between -1 and 1, and a value of 1 means that the two variables are perfectly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation coefficient\n",
    "sp.stats.pearsonr(b1,b2)[0] # Second return value is p-value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
