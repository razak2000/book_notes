{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical inference, the practice of making predictions about a large group based on smaller samples, is traditionally broken into two segments, **estimation and hypothesis testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Estimation provides values for specific things that you may be interested in, such as mean or variance, <font color='blue'>with a provided confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A confidence interval provides a region within which you can expect to find the true value of the parameter you estimated, as an estimation will almost never be exact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals use <font color='blue'>a set confidence level to choose how wide the interval should be, to achieve a higher confidence, we must report a wider interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Hypothesis testing provides a different focus, detailing a framework for statistical testing of hypothesized values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>By making an assertion of what a value should be, you create a testable hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that statistical tests are designed such that<font color='blue'> if all the pre-requisite conditions are true, you should get the right answer about the data a certain percentage of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you accept a hypothesis as true based on a test, that doesn't mean it's definitely true. It just means that <font color='blue'>you can know the probability you are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to introduce is the null hypothesis, commonly written as $H_0$. <font color='blue'>The null hypothesis is the default case, generally reflecting the current common conception of the world. The alternative hypothesis is the one you are testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hypotheses are easier to test than others. However, you will still not get a perfect answer all the time in this case, as there may be <font color='blue'>measurement error in the counting, albiet quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis cannot be vague, otherwise how will it be tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Hypotheses should be very specific</font> and the type of test needed should follow quickly from the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The following are the main steps in hypothesis testing:\n",
    "\n",
    "1. <font color='blue'>State the hypothesis and the alternative to the hypothesis\n",
    "2. <font color='blue'>Identify the appropriate test statistic and its distribution.</font> Ensure that any assumptions about the data are met <font color='blue'>(stationarity, normality, etc.)\n",
    "3. Specify the <font color='blue'>significance level, $\\alpha$\n",
    "4. From $\\alpha$ and the distribution <font color='blue'>compute the 'critical value'.\n",
    "5. <font color='blue'>Collect the data and calculate the test statistic\n",
    "6. <font color='blue'>Compare test statistic with critical value and decide whether to accept or reject the hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we state the hypothesis that we wish to test. We do this by identifying a **null hypothesis** and an **alternative hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The null hypothesis, $H_0$, is the one that we want to test, while the alternative hypothesis, $H_A$, is the hypothesis that is accepted in the case where $H_0$ is rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to test whether the mean return of Microsoft stock is positive. <font color='blue'>The parameter that we are testing is denoted by $\\theta$ and the proposed value of the parameter is denoted by $\\theta_0$, which in this case is equal to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>So we say that our $H_0$ is $\\theta = \\theta_0$, that the returns are negative, and our $H_A$ is $\\theta \\neq \\theta_0$. \n",
    "\n",
    "<font color='blue'>Including this formation, there are three possible ways to formulate null and alternative hypotheses:\n",
    "1. $H_0: \\theta = \\theta_0$ versus $H_A: \\theta \\neq \\theta_0$ <font color='blue'>(A \"not equal to\" alternative hypothesis)\n",
    "2. $H_0: \\theta \\leq \\theta_0$ versus $H_A: \\theta > \\theta_0$ <font color='blue'>(A \"greater than\" alternative hypothesis)\n",
    "3. $H_0: \\theta \\geq \\theta_0$ versus $H_A: \\theta < \\theta_0$ <font color='blue'>(A \"less than\" alternative hypothesis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example follows the first formulation of a hypothesis test. <font color='blue'>This is a **two-sided hypothesis test** (or **two-tailed hypothesis test**). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second and third formulations are examples of <font color='blue'>a **one-sided hypothesis test** (or **one-tailed hypothesis test**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a one-sided test, we reject the null in favor of the alternative only if the data indicates that $\\theta$ is repectively greater than or less than $\\theta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-sided test rejects the null in favor of the alternative if the data indicates that $\\theta$ is either greater or less than $\\theta_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we were to write out our hypothesis for MSFT in more qualitative terms, we would have:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "H_0 &:& \\text{The mean return on Microsoft stock is $0$}\\\\\n",
    "H_A &:& \\text{The mean return on Microsoft stock is not $0$}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>When forming a hypothesis test, the null and alternative hypothesis must be complementary to each other. Between them they must cover all values of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Regardless of the type of hypothesis test we are performing, we always test the null hypothesis as if $\\theta = \\theta_0$.</font> In the case of either of the one-tailed tests, this will still provide more than enough evidence for us to make a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if $H_0: \\theta \\leq 0$, $H_A: \\theta > 0$, and we have enough evidence to reject $H_0: \\theta = 0$ in favor of $H_A: \\theta > 0$, then this holds true for all values less than $0$ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common type of hypothesis test is the two-tailed, \"not equal to\", hypothesis test, because it presents a neutral view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The one-tailed hypothesis tests are less neutral than the \"not equal to\" test, reflecting the thoughts of the tester. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>One-tailed tests are often used to test \"hoped for\" results or results that the testers have a prior idea about.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2015-01-01\"\n",
    "end = \"2016-01-01\"\n",
    "pricing_sample = get_pricing(\"MSFT\", start_date = start, end_date = end, fields = 'price')\n",
    "\n",
    "#transform it into returns\n",
    "returns_sample = pricing_sample.pct_change()[1:]\n",
    "\n",
    "# plot it\n",
    "plt.plot(pricing_sample.index, pricing_sample.values)\n",
    "plt.ylabel('Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(returns_sample.index, returns_sample.values)\n",
    "plt.ylabel('Returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we can't look at the actual data generating process behind the returns, <font color='blue'>we can only sample returns on some limited time period. \n",
    "\n",
    "Because we only observe a sample, that sample may or may not reflect the true state of the underlying process. Because of this uncertainty we need to use statistical tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A test statistic usually takes the following form:\n",
    "\n",
    "<font color='blue'>$$ \\text{Test statistic} = \\frac{\\text{Sample statistic} - \\text{Value of the population parameter under $H_0$ ($\\theta_0$)}}{\\text{Standard error of the sample statistic}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A test statistic is calculated based on sample data and is compared to its probability distribution to determine whether to reject or not reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are testing the mean return on MSFT stock, we can use the sample mean, $\\bar{X}_\\mu$, as our sample statistic. \n",
    "\n",
    "<font color='blue'>We calculate the standard error of the sample mean as $\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}$ if we know the standard deviation, $\\sigma$, or as $s_{\\bar{X}} = \\frac{s}{\\sqrt{n}}$, where $s$ is the sample standard deviation. \n",
    "\n",
    "So using these definitions, our test statistic can be calculated as: $ \\frac{\\bar{X}_\\mu - \\theta_0}{s_{\\bar{X}}} = \\frac{\\bar{X}_\\mu - 0}{s/\\sqrt{n}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four most common distributions for test statistics are as follows:\n",
    "\n",
    "* The $t$-distribution<font color='blue'> ($t$-test)\n",
    "* The standard normal distribution <font color='blue'>($z$-test)\n",
    "* The chi-square ($\\chi^2$) distribution <font color='blue'>($\\chi^2$-test)\n",
    "* The $F$-distribution <font color='blue'>($F$-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we identify the appropriate test statistic and probability distribution, we need to <font color='blue'>specify the **significance level** of the test, $\\alpha$. \n",
    "\n",
    "<font color='blue'>The values that we compare our test statistic to in order to reject or fail to reject \n",
    "the $H_0$ are determined based on our $\\alpha$ value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Our significance level is equal to the probability of a Type I error (a \"false positive\") occuring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The probability of a Type II error (a \"false negative\") occuring is denoted by $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If we try to decrease the probability of a Type I error occuring, we increase the probability of a Type II error occuring, resulting in a tradeoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The only way to reduce the probability of both a Type I and a Type II error occuring is to increase the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conventional significance levels are $0.1$, $0.05$, and $0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Rejecting the null at $0.1$ mean that we have some evidence null is false, $0.05$ means we have strong evidence null is false, rejecting at $0.01$ we have very strong evidence that null is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The critical value for our test statistic is the value that we compare the test statistic to when deciding whether to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we reject the null, we say that the result is<font color='blue'> **statistically significant**</font>, while if we fail to reject the null, we say that the result is <font color='blue'>**not statistically significant**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The critical value of a test is determined based on the  $\\alpha$  of our hypothesis test as well as the chosen distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, say that $\\alpha = 0.05$, so our significance level is $0.05$. <font color='blue'>With a one-sided $z$-test, there are two different ways to see the critical values:\n",
    "\n",
    "* If we test $H_0$: $\\theta \\leq \\theta_0$, $H_A$: $\\theta > \\theta_0$ at $\\alpha = 0.05$, our critical value is $z_{0.05} = 1.645$. So we compare our test statistic and we reject the null hypothesis if $z > 1.645$.\n",
    "* If we test $H_0$: $\\theta \\geq \\theta_0$, $H_A$: $\\theta < \\theta_0$ at $\\alpha = 0.05$, our critical value is $-z_{0.05} = -1.645$. As such, we compare our test statistic and we reject the null hypothesis if $z < -1.645$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A two-sided test is a slightly different situation. Since it is two-sided, there are two rejection points, negative and positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Our $\\alpha$ is $0.05$, so the total probability of a Type I error must sum to $0.05$. As such, we split $0.05$ in half so that our two rejection points are $z_{0.025}$ and $-z_{0.025}$ for the positive and negative critical values, respectively.\n",
    "\n",
    "For a $z$-test, these values are $1.96$ and $-1.96$. Thus, we reject the null if $z < -1.96$ or if $z > 1.96$. If we find that $-1.96 \\leq z \\leq 1.96$, we fail to reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>When conducting a hypothesis test, you can also use a **$p$-value** to determine the result. A $p$-value is the minimum level of significance where you can reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A $p$-value only makes sense when compared to the significance value. If a $p$-value is less than $\\alpha$, we reject the null and otherwise we do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Lower $p$-values do not make something \"more statistically significant\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of statistical outputs will calculate a $p$-value for you, but it is also possible to calculate it manually. <font color='blue'>The calculation depends both on your type of hypothesis test and the CDF of the distribution you are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>To manually calculate a $p$-value, do the following:\n",
    "\n",
    "* <font color='blue'>In a 'less than or equal to' hypothesis test, the $p$-value is $1 - CDF(\\text{Test Statistic})$\n",
    "* <font color='blue'>In a 'greater than or equal to' hypothesis test, the $p$-value is $CDF(\\text{Test Statistic})$\n",
    "* <font color='blue'>In a 'not equal to' hypothesis test, the $p$-value is $2 * 1 - CDF(|\\text{Test Statistic}|)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significance values tie very nicely into confidence intervals. <font color='blue'>A confidence interval provides us with an estimate for a parameter's possible range in values given a certain significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a standard normal distribution and mark the critical regions with shading\n",
    "x = np.linspace(-3, 3, 100)\n",
    "norm_pdf = lambda x: (1/np.sqrt(2 * np.pi)) * np.exp(-x * x / 2)\n",
    "y = norm_pdf(x)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True)\n",
    "ax.plot(x, y)\n",
    "ax.fill_between(x, 0, y, where = x > 1.96)\n",
    "ax.fill_between(x, 0, y, where = x < -1.96)\n",
    "plt.title('Rejection regions for a two-tailed hypothesis test at 95% confidence')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Keep in mind that any negative characteristics of the data will negatively affect our hypothesis test and possibly render it invalid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the case of our test of MSFT returns, we may run into <font color='blue'>issues of time-period bias, or of look-ahead bias (if we prepare the test incorrectly). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always with historical data, <font color='blue'>the data that we work with may result in a specific test result that may not hold for the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We also have to make sure that the data does not include any values that we would not have known during the time period we are testing (though this is more of an issue when comparing multiple things with hypothesis tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(returns_sample)\n",
    "test_statistic = ((returns_sample.mean() - 0) /\n",
    "                (returns_sample.std()/np.sqrt(n)))\n",
    "print 't test statistic: ', test_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>In order to make the statistical decision for the test, we compare our test statistic to our critical value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we chose instead to determine the result of this hypothesis test with a  p -value, we would calculate the  p -value in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "p_val = 2 * (1 - t.cdf(test_statistic, n - 1))\n",
    "print 'P-value is: ', p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <font color='blue'>$z$-distribution, or a standard normal distribution,</font> is an essential probability distribution in finance.many fundamental methods require an assumption of normality in order to proceed. <font color='blue'>However, in most cases a $z$-distribution will be inappropriate for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We rarely know the true parameter values (mean and variance) of our data and must rely upon approximations. In these cases, we should use the $t$-distribution, and approximation of the normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The $t$-distribution is more forgiving when it comes to small sample sizes and is meant to be used with sample mean and variance. It has fatter tails and a lower peak, giving more flexibility compared to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Both the $t$ and $z$-distributions rely upon an underlying assumption of normality</font>, which is typically the case when we are analyzing financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We can use a hypothesis test to determine whether the means of several data-sets are statistically different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = [\"SPY\", \"AAPL\"]\n",
    "start = '2015-01-01'\n",
    "end = '2016-01-01'\n",
    "pricing_sample = get_pricing(symbol_list, start_date = start, end_date = end, fields='price')\n",
    "pricing_sample.columns = map(lambda x: x.symbol, pricing_sample.columns)\n",
    "returns_sample = pricing_sample.pct_change()[1:]\n",
    "returns_sample.plot()\n",
    "plt.ylabel('Returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing two means, our hypothesis tests are stated as the following:\n",
    "\n",
    "1. $H_0: \\mu_1 - \\mu_2 = \\theta_0, \\ H_A: \\mu_1 - \\mu_2 \\neq \\theta_0$\n",
    "2. $H_0: \\mu_1 - \\mu_2 \\leq \\theta_0, \\ H_A: \\mu_1 - \\mu_2 > \\theta_0$\n",
    "3. $H_0: \\mu_1 - \\mu_2 \\geq \\theta_0, \\ H_A: \\mu_1 - \\mu_2 < \\theta_0$\n",
    "    \n",
    "    Where $\\mu_1, \\mu_2$ are the respective means of SPY and AAPL and $\\theta_0$ is the parameter we are testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='blue'>If we assume that the population variances are equal, our test statistic is calculated as:\n",
    "$ t = \\frac{(\\bar{X}_1 - \\bar{X}_2) - (\\mu_1 - \\mu_2)}{(\\frac{s_p^2}{n_1} + \\frac{s_p^2}{n_2})^{1/2}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{(\\frac{s_p^2}{n_1} + \\frac{s_p^2}{n_2})^{1/2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>With $s_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2)}{n_1 + n_2 - 2}$ as the estimator of the common variance, known as the pooled variance, and $n_1 + n_2 - 2$ as the number of degrees of freedom ($n_1 - 1$ and $n_2 - 1$ for each dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A typical $t$-test on a mean assumes that all variances involved are equal with underlying normal distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If we are assuming that the variances are not equal, we have to calculate our test statistic differently. Our test statistic in this case is:\n",
    "$$ t = \\frac{(\\bar{X}_1 - \\bar{X}_2) - (\\mu_1 - \\mu_2)}{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^{1/2}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^{1/2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Where the number of degrees of freedom used to find the critical statistic is the modified degrees of freedom, the number of values that are free to vary, $df = \\frac{(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2})^2}{\\frac{(s_1^2/n_1)^2}{n_1} + \\frac{(s_2^2/n_2)^2}{n_2}}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>This preserves the underlying normality of the data being tested while accounting for differing variances. Calculating the statistic this way removes a lot of problems that can occur if we have unequal variances, especially if the sample sizes of the underlying data differ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specific case of a $t$-test is referred to as [\"Welch's unequal variances $t$-test\"](https://en.wikipedia.org/wiki/Welch%27s_t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mean values\n",
    "mu_spy, mu_aapl = returns_sample.mean()\n",
    "s_spy, s_aapl = returns_sample.std()\n",
    "n_spy = len(returns_sample['SPY'])\n",
    "n_aapl = len(returns_sample['AAPL'])\n",
    "\n",
    "test_statistic = ((mu_spy - mu_aapl) - 0)/((s_spy**2/n_spy) + (s_aapl**2/n_aapl))**0.5\n",
    "df = ((s_spy**2/n_spy) + (s_aapl**2/n_aapl))**2/(((s_spy**2 / n_spy)**2 /n_spy)+((s_aapl**2 / n_aapl)**2/n_aapl))\n",
    "\n",
    "print 't test statistic: ', test_statistic\n",
    "print 'Degrees of freedom (modified): ', df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If we want to test the variances of populations, we need to use a different distribution from the $t$ and $z$ distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances must by definition be greater than (or equal to) $0$ and fact that <font color='blue'>the distributions we have worked with up until now allow negative values makes them unviable as testing distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of $t$ and $z$-distributions, we will be working with <font color='blue'>$\\chi^2$ distributions for single variance tests and $F$ distributions for comparisons of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>These distributions are bounded below by $0$</font>, making them viable for testing in this manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Just like with all of our other hypothesis tests, tests of a single variance can take on three forms:\n",
    "\n",
    "1. $H_0: \\sigma^2 = \\sigma_0^2, \\ H_A: \\sigma^2 \\neq \\sigma_0^2$\n",
    "2. $H_0: \\sigma^2 \\leq \\sigma_0^2, \\ H_A: \\sigma^2 > \\sigma_0^2$\n",
    "3. $H_0: \\sigma^2 \\geq \\sigma_0^2, \\ H_A: \\sigma^2 < \\sigma_0^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The $\\chi^2$ distribution is a family of functions with each different formulation determined by the number of degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The shape of the distribution is different for every different value of the number of degrees of freedom, $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# Here we show what a chi-square looks like\n",
    "x = np.linspace(0, 8, 100)\n",
    "y_1 = chi2.pdf(x, 1)\n",
    "y_2 = chi2.pdf(x, 2)\n",
    "y_3 = chi2.pdf(x, 3)\n",
    "y_4 = chi2.pdf(x, 4)\n",
    "y_6 = chi2.pdf(x, 6)\n",
    "y_9 = chi2.pdf(x, 9)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y_1, label = 'k = 1')\n",
    "ax.plot(x, y_2, label = 'k = 2')\n",
    "ax.plot(x, y_3, label = 'k = 3')\n",
    "ax.plot(x, y_4, label = 'k = 4')\n",
    "ax.plot(x, y_6, label = 'k = 6')\n",
    "ax.plot(x, y_9, label = 'k = 9')\n",
    "ax.legend()\n",
    "plt.title('Chi-Square distribution with k degrees of freedom')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='blue'>We calculate the $\\chi^2$ test statistic as $ \\chi^2 = \\frac{(n - 1)s^2}{\\sigma_0^2} $\n",
    "\n",
    "  where $s^2$ is the sample variance and $n$ is the size of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of degrees of freedom is $n - 1$ and this is used in conjunction with the test statistic to determine the critical value(s) of our $\\chi^2$ hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2015-01-01\"\n",
    "end = \"2016-01-01\"\n",
    "pricing_sample = get_pricing(\"MSFT\", start_date = start, end_date = end, fields = 'price')\n",
    "returns_sample = pricing_sample.pct_change()[1:]\n",
    "plt.plot(returns_sample.index, returns_sample.values)\n",
    "plt.ylabel('Returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to use $\\alpha = 0.01$ to test whether the variance of MSFT is less than or equal to $0.0001$ (that the standard deviation, or risk, is less than or equal to $0.01$).\n",
    "\n",
    "$$ H_0: \\sigma^2 \\leq 0.0001, \\ H_A: \\sigma^2 > 0.0001 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic = (len(returns_sample) - 1) * returns_sample.std()**2 / 0.0001\n",
    "print 'Chi-square test statistic: ', test_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the critical value directly because our df is too high for most chisquare tables\n",
    "crit_value = chi2.ppf(0.99, len(returns_sample) - 1)\n",
    "print 'Critical value at a = 0.01 with 251 df: ', crit_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are using the 'less than or equal to' formulation of a one-sided hypothesis test, we reject the null hypothesis if our test statistic is greater than the critical value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We can compare the variances of two separate things using the $F$ distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing a comparison of \n",
    "variances using an $F$-test, the hypothesis formulations are:\n",
    "\n",
    "1. $H_0: \\sigma_1^2 = \\sigma_2^2, \\ H_A: \\sigma_1^2 \\neq \\sigma_2^2$\n",
    "2. $H_0: \\sigma_1^2 \\leq \\sigma_2^2, \\ H_A: \\sigma_1^2 > \\sigma_2^2$\n",
    "3. $H_0: \\sigma_1^2 \\geq \\sigma_2^2, \\ H_A: \\sigma_1^2 < \\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $F$ distribution is similar to the $\\chi^2$ distribution in that it is asymmetrical and bounded below by $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The $F$ distribution is defined with two different values of degrees of freedom. For the purposes of hypothesis testing, each one correlates to one of the factors that we are comparing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>An $F$ distribution can be constructed from two separate $\\chi^2$ distributions. $X$ is a $F$ random variable if it can be written as $X = \\frac{Y_1/d_1}{Y_2/d_2}$, where $Y_1$ and $Y_2$ are $\\chi^2$ random variables with degrees of freedom $d_1$ and $d_2$, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The an $F$ random variable is essentially a ratio of variances. Consequently, constructing the $F$ test statistic is done by taking the ratio of the sample variances of the data that we want to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply choose $\\sigma_1^2$ and $\\sigma_2^2$ to represent either of the variances that we are comparing in order so that<font color='blue'> our F-statistic is greater than $1$. \n",
    "$$ F = \\frac{s_1^2}{s_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = [\"SPY\", \"AAPL\"]\n",
    "start = \"2015-01-01\"\n",
    "end = \"2016-01-01\"\n",
    "pricing_sample = get_pricing(symbol_list, start_date = start, end_date = end, fields = 'price')\n",
    "pricing_sample.columns = map(lambda x: x.symbol, pricing_sample.columns)\n",
    "returns_sample = pricing_sample.pct_change()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take returns from above, AAPL and SPY, and compare their variances\n",
    "spy_std_dev, aapl_std_dev = returns_sample.std()\n",
    "print 'SPY standard deviation is: ', spy_std_dev\n",
    "print 'AAPL standard deviation is: ', aapl_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic = (aapl_std_dev / spy_std_dev)**2\n",
    "print \"F Test statistic: \", test_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since these values are taken over the same time period, they will have the same number of degrees of freedom\n",
    "df1 = len(returns_sample['AAPL']) - 1\n",
    "df2 = len(returns_sample['SPY']) - 1\n",
    "\n",
    "print 'Degrees of freedom for SPY: ', df2\n",
    "print 'Degrees of freedom for AAPL: ', df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "upper_crit_value = f.ppf(0.975, df1, df2)\n",
    "lower_crit_value = f.ppf(0.025, df1, df2)\n",
    "print 'Upper critical value at a = 0.05 with df1 = {0} and df2 = {1}: '.format(df1, df2), upper_crit_value\n",
    "print 'Lower critical value at a = 0.05 with df1 = {0} and df2 = {1}: '.format(df1, df2), lower_crit_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More common test statistics and tests can be found [here](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Common_test_statistics)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
