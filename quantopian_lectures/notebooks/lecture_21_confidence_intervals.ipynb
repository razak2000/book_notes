{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we want to know about a population mean, but we can only calculate a sample mean. We then want to <font color='blue'>use the sample mean to estimate the population mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We use confidence intervals in an attempt to determine how accurately our sample mean estimates the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set a seed here so our runs are consistent\n",
    "np.random.seed(10)\n",
    "\n",
    "# Let's define some 'true' population parameters, we'll pretend we don't know these.\n",
    "POPULATION_MU = 64\n",
    "POPULATION_SIGMA = 5\n",
    "\n",
    "# Generate our sample by drawing from the population distribution\n",
    "sample_size = 10\n",
    "heights = np.random.normal(POPULATION_MU, POPULATION_SIGMA, sample_size)\n",
    "print heights\n",
    "mean_height = np.mean(heights)\n",
    "print 'sample mean: ', mean_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately simply reporting the sample mean doesn't do much for us, as we don't know how it relates to the population mean. To get a sense for how it might relate, we can look for how much variance there is in our sample. Higher variance indicates instability and uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>to really get a sense of how our sample mean relates to the population mean we need to compute a standard error. \n",
    "\n",
    "<font color='blue'>The standard error is a measure of the variance of the sample mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Computing a standard error involves assuming that the way you sample is unbaised, and that the data are normal and independent. If these conditions are violated, your standard error will be wrong. There are ways of testing for this and correcting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T<font color='blue'>he formula for standard error is $SE = \\frac{\\sigma}{\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = np.std(heights) / np.sqrt(sample_size)\n",
    "print 'standard error: ', SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>There is a function in scipy's stats library for calculating the standard error. Note that this function by default contains a degrees-of-freedom correction that is often not necessary (for large enough samples, it is effectively irrelevant). You can omit the correction by setting the parameter ddof to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sem(heights, ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Assuming our data are normally distributed, we can use the standard error to compute our confidence interval. To do this we first set our desired confidence level, say 95%, we then determine how many standard deviations contain 95% of the mass. Turns out that the 95% of the mass lies between -1.96 and 1.96 on a standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>When the samples are large enough (generally > 30 is taken as a threshold) the Central Limit Theorem applies and normality can be safely assumed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>if sample sizes are smaller, a safer approach is to use a  t -distribution with appropriately specified degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The actual way to compute the values is by using a cumulative distribution function (CDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Be careful when applying the Central Limit Theorem, however, as many datasets in finance are fundamentally non-normal and it is not safe to apply the theorem casually or without attention to subtlety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the x axis\n",
    "x = np.linspace(-5,5,100)\n",
    "# Here's the normal distribution\n",
    "y = stats.norm.pdf(x,0,1)\n",
    "plt.plot(x,y)\n",
    "\n",
    "# Plot our bounds\n",
    "plt.vlines(-1.96, 0, 1, colors='r', linestyles='dashed')\n",
    "plt.vlines(1.96, 0, 1, colors='r', linestyles='dashed')\n",
    "\n",
    "# Shade the area\n",
    "fill_x = np.linspace(-1.96, 1.96, 500)\n",
    "fill_y = stats.norm.pdf(fill_x, 0, 1)\n",
    "plt.fill_between(fill_x, fill_y)\n",
    "\n",
    "plt.xlabel('$\\sigma$')\n",
    "plt.ylabel('Normal PDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rather than reporting our sample mean without any sense of the probability of it being correct, <font color='blue'>we can compute an interval and be much more confident that the population mean lies in that interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>To do this we take our sample mean  μ  and report  (μ−1.96SE,μ+1.96SE) . This works because assuming normality, that interval will contain the population mean 95% of the time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any given case, <font color='blue'>the true value of the estimate and the bounds of the confidence interval are fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The  t -distribution requires the extra parameter degrees of freedom (d.o.f), which is the size of the sample minus one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the  t -values needed (analogous to the  ±1.96  used above) are being calculated from the inverted cumulative density function, <font color='blue'>the `ppf` in scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8309)\n",
    "n = 100 # number of samples to take\n",
    "samples = [np.random.normal(loc=0, scale=1, size=100) for _ in range(n)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "for i in np.arange(1, n, 1):\n",
    "    sample_mean = np.mean(samples[i])  # calculate sample mean\n",
    "    se = stats.sem(samples[i])  # calculate sample standard error\n",
    "    h = se*stats.t.ppf((1+0.95)/2, len(samples[i])-1) # calculate t; 2nd param is d.o.f. \n",
    "    sample_ci = [sample_mean - h, sample_mean + h]\n",
    "    if ((sample_ci[0] <= 0) and (0 <= sample_ci[1])):\n",
    "        plt.plot((sample_ci[0], sample_ci[1]), (i, i), color='blue', linewidth=1);\n",
    "        plt.plot(np.mean(samples[i]), i, 'bo');\n",
    "    else:\n",
    "        plt.plot((sample_ci[0], sample_ci[1]), (i, i), color='red', linewidth=1);\n",
    "        plt.plot(np.mean(samples[i]), i, 'ro');\n",
    "plt.axvline(x=0, ymin=0, ymax=1, linestyle='--', label = 'Population Mean');\n",
    "plt.legend(loc='best');\n",
    "plt.title('100 95% Confidence Intervals for mean of 0');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error SE was already calculated\n",
    "t_val = stats.t.ppf((1+0.95)/2, 9)  # d.o.f. = 10 - 1\n",
    "print 'sample mean height:', mean_height\n",
    "print 't-value:', t_val\n",
    "print 'standard error:', SE\n",
    "print 'confidence interval:', (mean_height - t_val * SE, mean_height + t_val * SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that <font color='blue'>at a corresponding level of confidence, the interval calculated using the normal distribution is narrower than the interval calcuated using the  t -distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Confidence intervals allow us to set our desired confidence, and then report a range that will likely contain the population mean. The higher our desired confidence, the larger range we report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "sample_sizes = [10, 100, 1000]\n",
    "for s in sample_sizes:\n",
    "    heights = np.random.normal(POPULATION_MU, POPULATION_SIGMA, s)\n",
    "    SE = np.std(heights) / np.sqrt(s)\n",
    "    print stats.norm.interval(0.95, loc=mean_height, scale=SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "heights = np.random.normal(POPULATION_MU, POPULATION_SIGMA, sample_size)\n",
    "SE = np.std(heights) / np.sqrt(sample_size)\n",
    "(l, u) = stats.norm.interval(0.95, loc=np.mean(heights), scale=SE)\n",
    "\n",
    "print (l, u)\n",
    "\n",
    "plt.hist(heights, bins=20)\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Just for plotting\n",
    "y_height = 5\n",
    "plt.plot([l, u], [y_height, y_height], '-', color='r', linewidth=4, label='Confidence Interval')\n",
    "plt.plot(np.mean(heights), y_height, 'o', color='r', markersize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The computation of a standard deviation, standard error, and confidence interval all rely on certain assumptions.</font> If these assumptions are violated then the 95% confidence interval will not necessarily contain the population parameter 95% of the time. We say that in this case the confidence interval is <font color='blue'>miscalibrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If your data generating process is autocorrelated, then estimates of standard deviation will be wrong. This is because autocorrelated processes tend to produce more extreme values than normally distributed processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to new values being dependent on previous values, series that are already far from the mean are likely to stay far from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autocorrelated_data(theta, mu, sigma, N):\n",
    "    # Initialize the array\n",
    "    X = np.zeros((N, 1))\n",
    "    \n",
    "    for t in range(1, N):\n",
    "        # X_t = theta * X_{t-1} + epsilon\n",
    "        X[t] = theta * X[t-1] + np.random.normal(mu, sigma)\n",
    "    return X\n",
    "\n",
    "X = generate_autocorrelated_data(0.5, 0, 1, 100)\n",
    "\n",
    "plt.plot(X);\n",
    "plt.xlabel('t');\n",
    "plt.ylabel('X[t]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that for larger sample sizes, you should see the sample mean asymptotically converge to zero. This is because the process is still centered around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = np.zeros(200-1)\n",
    "for i in range(1, 200):\n",
    "    X = generate_autocorrelated_data(0.5, 0, 1, i * 10)\n",
    "    sample_means[i-1] = np.mean(X)\n",
    "    \n",
    "plt.bar(range(1, 200), sample_means);\n",
    "plt.xlabel('Sample Size');\n",
    "plt.ylabel('Sample Mean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unadjusted_interval(X):\n",
    "    T = len(X)\n",
    "    # Compute mu and sigma MLE\n",
    "    mu = np.mean(X)\n",
    "    sigma = np.std(X)\n",
    "    SE = sigma / np.sqrt(T)\n",
    "    # Compute the bounds\n",
    "    return stats.norm.interval(0.95, loc=mu, scale=SE)\n",
    "\n",
    "# We'll make a function that returns true when the computed bounds contain 0\n",
    "def check_unadjusted_coverage(X):\n",
    "    l, u = compute_unadjusted_interval(X)\n",
    "    # Check to make sure l <= 0 <= u\n",
    "    if l <= 0 and u >= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "trials = 500\n",
    "times_correct = 0\n",
    "for i in range(trials):\n",
    "    X = generate_autocorrelated_data(0.5, 0, 1, T)\n",
    "    if check_unadjusted_coverage(X):\n",
    "        times_correct += 1\n",
    "    \n",
    "print 'Empirical Coverage: ', times_correct/float(trials)\n",
    "print 'Expected Coverage: ', 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the coverage is wrong. <font color='blue'>In this case we'd need to do what's known as a Newey-West correction on our standard error estimate to account for the autocorrelation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>In practice it's important to check for the assumptions you make. It is quick and easy to check if your data are stationary (which implies not autocorrelated), and it can save you a lot of pain and suffering to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A normality test such as Jarque Bera will also be a good idea, as it may detect certain distribution properties which may violate assumptions of many following statistical analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
