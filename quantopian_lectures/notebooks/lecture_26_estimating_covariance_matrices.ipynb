{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully measuring volatility would allow for more accurate modeling of the returns and more stable investments leading to greater returns, but <font color='blue'>forecasting volatility accurately is a difficult problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Volatility needs to be forward-looking and predictive in order to make smart decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, simply taking the historical standard deviation of an individual asset's returns falls short when we take into account need for robustness to the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>To model how a portfolio overall changes, it is important to look not only at the volatility of each asset in the portfolio, but also at the pairwise covariances of every asset involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between two or more assets provides valuable insights and a path towards reduction of overall portfolio volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>A large number of assets with low covariance would assure they decrease or increase independently of each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics and probability, <font color='blue'>the covariance is a measure of the joint variability of two random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>When random variables exhibit similar behavior, there tends to be a high covariance between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we express the covariance of X with respect to Y as:\n",
    "<font color='blue'>$ COV(X, Y) = E[(X - E[X])(Y - E[Y])]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If two assets have a high covariance, they will generally behave the same way. \n",
    "\n",
    "<font color='blue'>Assets with particularly high covariance can essentially replace each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> We use covariances to quantify the joint risk of assets, forming how we view the risk of an entire portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is key is that investing in assets that have high pairwise covariances provides little diversification because of how closely their fluctuations are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn import covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random values of x\n",
    "X = np.random.normal(size = 1000)\n",
    "epsilon = np.random.normal(0, 3, size = len(X))\n",
    "Y = 5*X + epsilon\n",
    "\n",
    "product = (X - np.mean(X))*(Y - np.mean(Y))\n",
    "expected_value = np.mean(product)\n",
    "\n",
    "print 'Value of the covariance between X and Y:', expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.var(X), np.var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance matrices are symmetric, since <font color='blue'>$COV(X, Y) = COV(Y, X)$,</font> which is why the off-diagonals mirror each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of X and y\n",
    "from statsmodels import regression\n",
    "import statsmodels.api as sm\n",
    "def linreg(X,Y):\n",
    "    # Running the linear regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = regression.linear_model.OLS(Y, X).fit()\n",
    "    a = model.params[0]\n",
    "    b = model.params[1]\n",
    "    X = X[:, 1]\n",
    "\n",
    "    # Return summary of the regression and plot results\n",
    "    X2 = np.linspace(X.min(), X.max(), 100)\n",
    "    Y_hat = X2 * b + a\n",
    "    plt.scatter(X, Y, alpha=0.3) # Plot the raw data\n",
    "    plt.plot(X2, Y_hat, 'r', alpha=0.9);  # Add the regression line, colored in red\n",
    "    plt.xlabel('X Value')\n",
    "    plt.ylabel('Y Value')\n",
    "    return model.summary()\n",
    "\n",
    "linreg(X, Y)\n",
    "plt.scatter(X, Y)\n",
    "plt.title('Scatter plot and linear equation of x as a function of y')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend(['Linear equation', 'Scatter Plot']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If we take the covariance between $N$ assets, we will get out a $N \\times N$ covariance matrix.\n",
    "$$ \\Sigma = \\left[\\begin{matrix}\n",
    "VAR(X_1) & COV(X_1, X_2) & \\cdots & COV(X_1, X_N) \\\\\n",
    "COV(X_2, X_0) & VAR(X_2) & \\cdots & COV(X_2, X_N) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "COV(X_N, X_1) & COV(X_N, X_2) & \\cdots & VAR(X_N)\n",
    "\\end{matrix}\\right] $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four asset example of the covariance matrix.\n",
    "start_date = '2016-01-01'\n",
    "end_date = '2016-02-01'\n",
    "\n",
    "returns = get_pricing(\n",
    "    ['SBUX', 'AAPL', 'GS', 'GILD'],\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    fields='price'\n",
    ").pct_change()[1:]\n",
    "returns.columns = map(lambda x: x.symbol, returns.columns)\n",
    "\n",
    "print 'Covariance matrix:'\n",
    "print returns.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the covariance of the assets in our portfolio to make sure we have an accurate picture of the risks involved in holding those assets togther."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Estimating the covariance matrix becomes critical when using methods that rely on it, as we cannot know the true statistical relationships underlying our chosen assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The stability and accuracy of these estimates are essential to getting stable weights that encapsulate our risks and intentions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, <font color='blue'>the most obvious way to calculate a covariance matrix estimate, the sample covariance, is notoriously unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>If we have fewer time observations of our assets than the number of assets ( T<N ), the estimate becomes especially unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The extreme values react more strongly to changes, and as the extreme values of the covariance jump around, our optimizers are perturbed, giving us inconsistent weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Even if we have more time elements than assets that we are trading, we can run into issues, as the time component may span multiple regimes, giving us covariance matrices that are still inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution in many cases is to<font color='blue'> use a robust formulation of the covariance matrix. If we can estimate a covariance matrix that still captures the relationships between assets and is simultaneously more stable, then we can have more faith in the output of our optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The concept of shrinkage stems from the need for stable covariance matrices. The basic way we \"shrink\" a matrix is to reduce the extreme values of the sample covariance matrix by pulling them closer to the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practically, <font color='blue'>we take a linear combination of the sample covariance covariance matrix a constant array representing the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Given a sample covariance matrix, $\\textbf{S}$, the mean variance, $\\mu$, and the shrinkage constant $\\delta$, the shrunk estimated covariance is mathematically defined as:   \n",
    "$(1 - \\delta)\\textbf{S} + \\delta\\mu\\textbf{1}$\n",
    " \n",
    "<font color='blue'>We restrict $\\delta$ such that $0 \\leq \\delta \\leq 1$ </font>making this a weighted average between the sample covariance and the mean variance matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value of  Î´  has been tackled several times. For our purposes, we will use the formulation by Ledoit and Wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [their paper](http://ledoit.net/honey.pdf), <font color='blue'>Ledoit and Wolf  proposed an optimal $\\delta$: \n",
    "$\\hat\\delta^* \\max\\{0, \\min\\{\\frac{\\hat\\kappa}{T},1\\}\\}$<br></font>\n",
    "$\\hat\\kappa$ has a mathematical formulation that is beyond the scope of this lecture, but you can find its definition in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The Ledoit-Wolf Estimator is the robust covariance estimate that uses this optimal $\\hat\\delta^*$ to shrink the sample covariance matrix.</font> We can draw an implementation of it directly from `scikit-learn` for easy use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the return data of assets. \n",
    "start = '2016-01-01'\n",
    "end = '2016-02-01'\n",
    "\n",
    "symbols = ['AAPL', 'MSFT', 'BRK-A', 'GE', 'FDX', 'SBUX']\n",
    "\n",
    "prices = get_pricing(symbols, start_date = start, end_date = end, fields = 'price')\n",
    "prices.columns = map(lambda x: x.symbol, prices.columns)\n",
    "returns = prices.pct_change()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_lw = covariance.ledoit_wolf(returns)[0]\n",
    "print in_sample_lw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We can quantify the difference between the in and out-of-sample estimates by taking the absolute difference element-by-element for the two matrices. We represent this mathematically as: \n",
    "$ \\frac{1}{n} \\sum_{i=1}^{n} |a_i - b_i| $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_start = '2016-02-01'\n",
    "oos_end = '2016-03-01'\n",
    "oos_prices = get_pricing(symbols, start_date = oos_start, end_date = oos_end, fields = 'price')\n",
    "oos_prices.columns = map(lambda x: x.symbol, oos_prices.columns)\n",
    "oos_returns = oos_prices.pct_change()[1:]\n",
    "out_sample_lw = covariance.ledoit_wolf(oos_returns)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_errors = sum(abs(np.subtract(in_sample_lw, out_sample_lw)))\n",
    "print \"Average Ledoit-Wolf error: \", np.mean(lw_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_errors = sum(abs(np.subtract(returns.cov().values, oos_returns.cov().values)))\n",
    "print 'Average sample covariance error: ', np.mean(sample_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Error improvement of LW over sample: {0:.2f}%'.format((np.mean(sample_errors/lw_errors)-1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(\n",
    "    data = pd.DataFrame({\n",
    "        'Sample Covariance Error': sample_errors,\n",
    "        'Ledoit-Wolf Error': lw_errors\n",
    "    })\n",
    ")\n",
    "plt.title('Box Plot of Errors')\n",
    "plt.ylabel('Error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2016-01-01'\n",
    "end_date = '2017-06-01'\n",
    "\n",
    "symbols = [\n",
    "    'SPY', 'XLF', 'XLE', 'XLU','XLK', 'XLI', 'XLB', 'GE', 'GS', 'BRK-A', 'JPM', 'AAPL', 'MMM', 'BA',\n",
    "    'CSCO','KO', 'DIS','DD', 'XOM', 'INTC', 'IBM', 'NKE', 'MSFT', 'PG', 'UTX', 'HD', 'MCD', 'CVX', \n",
    "    'AXP','JNJ', 'MRK', 'CAT', 'PFE', 'TRV', 'UNH', 'WMT', 'VZ', 'QQQ', 'BAC', 'F', 'C', 'CMCSA',\n",
    "    'MS', 'ORCL', 'PEP', 'HON', 'GILD', 'LMT', 'UPS', 'HP', 'FDX', 'GD', 'SBUX'\n",
    "]\n",
    "\n",
    "prices = get_pricing(symbols, start_date=start_date, end_date=end_date, fields='price')\n",
    "prices.columns = map(lambda x: x.symbol, prices.columns)\n",
    "returns = prices.pct_change()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = returns.resample('M').first().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_covs = []\n",
    "lw_covs = []\n",
    "\n",
    "for i in range(1, len(dates)):\n",
    "    sample_cov = returns[dates[i-1]:dates[i]].cov().values\n",
    "    sample_covs.append(sample_cov)\n",
    "    \n",
    "    lw_cov = covariance.ledoit_wolf(returns[dates[i-1]:dates[i]])[0]\n",
    "    lw_covs.append(lw_cov)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw_diffs = []\n",
    "for pair in zip(lw_covs[:-1], lw_covs[1:]):\n",
    "    diff = np.mean(np.sum(np.abs(pair[0] - pair[1])))\n",
    "    lw_diffs.append(diff)\n",
    "    \n",
    "sample_diffs = []\n",
    "for pair in zip(sample_covs[:-1], sample_covs[1:]):\n",
    "    diff = np.mean(np.sum(np.abs(pair[0] - pair[1])))\n",
    "    sample_diffs.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dates[2:], lw_diffs)\n",
    "plt.plot(dates[2:], sample_diffs)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.legend(['Ledoit-Wolf Errors', 'Sample Covariance Errors']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>the Ledoit-Wolf estimator would likely perform even better as the number of assets outpaces the number of observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
