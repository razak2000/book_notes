{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The Kalman filter is an algorithm that uses noisy observations of a system over time to estimate the parameters of the system (some of which are unobservable) and predict future observations. \n",
    "\n",
    "At each time step, it makes a prediction, takes in a measurement, and updates itself based on how the prediction and measurement compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is as follows:\n",
    "1. <font color='blue'>Take as input a mathematical model of the system,</font> i.e.\n",
    "  * the <font color='blue'>transition matrix</font>, which tells us how the system evolves from one state to another., this matrix is usually called $A$.\n",
    "      - For instance, if we are modeling the movement of a car, then the next values of position and velocity can be computed from the previous ones using kinematic equations. \n",
    "      - Alternatively, if we have a system which is fairly stable, we might model its evolution as a random walk. \n",
    "  * the <font color='blue'>observation matrix</font>, which tells us the next measurement we should expect given the predicted next state. This is denoted $H$.\n",
    "      - If we are measuring the position of the car, we just extract the position values stored in the state.     \n",
    "      - For a more complex example, consider estimating a linear regression model for the data. Then our state is the coefficients of the model, and we can predict the next measurement from the linear equation. \n",
    "  * <font color='blue'>any control factors</font> that affect the state transitions but are not part of the measurements. The control factors are summarized in a matrix $B$ with time-varying control vector $u_t$, which give the offset $Bu_t$.\n",
    "      - For instance, if our car were falling, gravity would be a control factor. If the noise does not have mean 0, it should be shifted over and the offset put into the control factors. \n",
    "  * <font color='blue'>covariance matrices of the transition noise (i.e. noise in the evolution of the system) and measurement noise, denoted $Q$ and $R$, respectively.\n",
    "2. <font color='blue'>Take as input an initial estimate of the state of the system and the error of the estimate, $\\mu_0$ and $\\sigma_0$.\n",
    "3.<font color='blue'> At each timestep:\n",
    "  * <font color='blue'>estimate the current state of the system $x_t$ using the transition matrix\n",
    "  * <font color='blue'>take as input new measurements $z_t$\n",
    "  * <font color='blue'>use the conditional probability of the measurements given the state, taking into account the uncertainties of the measurement and the state estimate, to update the estimated current state of the system $x_t$ and the covariance matrix of the estimate $P_t$\n",
    "\n",
    "\n",
    "It's very important for the algorithm to <font color='blue'>keep track of the covariances of its estimates. \n",
    "\n",
    "This way, it can give us a more nuanced result than simply a point value when we ask for it, and it can use its confidence to decide how much to be influenced by new measurements during the update process. \n",
    "\n",
    "<font color='blue'>The more certain it is of its estimate of the state, the more skeptical it will be of measurements that disagree with the state.\n",
    "\n",
    "By default, <font color='blue'>the errors are assumed to be normally distributed, and this assumption allows the algorithm to calculate precise confidence intervals. It can, however, be implemented for non-normal errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a Kalman filter and other useful libraries\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import poly1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a Kalman filter, we need to give it transition and observation matrices, transition and observation covariance matrices, and the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.1\n",
    "\n",
    "# Set up the filter\n",
    "kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # position is 1-dimensional, (x,v) is 2-dimensional\n",
    "                  initial_state_mean=[30,10],\n",
    "                  initial_state_covariance=np.eye(2),\n",
    "                  transition_matrices=[[1,tau], [0,1]],\n",
    "                  observation_matrices=[[1,0]],\n",
    "                  observation_covariance=3,\n",
    "                  transition_covariance=np.zeros((2,2)),\n",
    "                  transition_offsets=[-4.9*tau**2, -9.8*tau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simulation of a ball falling for 40 units of time (each of length tau)\n",
    "times = np.arange(40)\n",
    "actual = -4.9*tau**2*times**2\n",
    "\n",
    "# Simulate the noisy camera data\n",
    "sim = actual + 3*np.random.randn(40)\n",
    "\n",
    "# Run filter on camera data\n",
    "state_means, state_covs = kf.filter(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, state_means[:,0])\n",
    "plt.plot(times, sim)\n",
    "plt.plot(times, actual)\n",
    "plt.legend(['Filter estimate', 'Camera data', 'Actual'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Height');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variances of x and v, extracting the appropriate values from the covariance matrix\n",
    "plt.plot(times, state_covs[:,0,0])\n",
    "plt.plot(times, state_covs[:,1,1])\n",
    "plt.legend(['Var(x)', 'Var(v)'])\n",
    "plt.ylabel('Variance')\n",
    "plt.xlabel('Time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The Kalman filter can also do <i>smoothing</i>, which takes in all of the input data at once and then constructs its best guess for the state of the system in each period post factum. \n",
    "\n",
    "That is, it does not provide online, running estimates, but instead uses all of the data to estimate the historical state, which is useful if we only want to use the data after we have collected all of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use smoothing to estimate what the state of the system has been\n",
    "smoothed_state_means, _ = kf.smooth(sim)\n",
    "\n",
    "# Plot results\n",
    "plt.plot(times, smoothed_state_means[:,0])\n",
    "plt.plot(times, sim)\n",
    "plt.plot(times, actual)\n",
    "plt.legend(['Smoothed estimate', 'Camera data', 'Actual'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Kalman filter updates its estimates at every time step and tends to weigh recent observations more than older ones, a <font color='blue'>particularly useful application is estimation of rolling parameters of the data. \n",
    "\n",
    "<font color='blue'>When using a Kalman filter, there's no window length that we need to specify.\n",
    "\n",
    "This is useful for computing the moving average if that's what we are interested in, or for smoothing out estimates of other quantities. For instance, if we have already computed the moving Sharpe ratio, we can smooth it using a Kalman filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pricing data for a security\n",
    "start = '2013-01-01'\n",
    "end = '2015-01-01'\n",
    "x = get_pricing('LMT', fields='price', start_date=start, end_date=end)\n",
    "\n",
    "# Construct a Kalman filter\n",
    "kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = 0,\n",
    "                  initial_state_covariance = 1,\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.01)\n",
    "\n",
    "# Use the observed values of the price to get a rolling mean\n",
    "state_means, _ = kf.filter(x.values)\n",
    "state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "\n",
    "# Compute the rolling mean with various lookback windows\n",
    "mean30 = x.rolling(window = 30).mean()\n",
    "mean60 = x.rolling(window = 60).mean()\n",
    "mean90 = x.rolling(window = 90).mean()\n",
    "\n",
    "# Plot original data and estimated mean\n",
    "plt.plot(state_means)\n",
    "plt.plot(x)\n",
    "plt.plot(mean30)\n",
    "plt.plot(mean60)\n",
    "plt.plot(mean90)\n",
    "plt.title('Kalman filter estimate of average')\n",
    "plt.legend(['Kalman Estimate', 'X', '30-day Moving Average', '60-day Moving Average','90-day Moving Average'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(state_means[-200:])\n",
    "plt.plot(x[-200:])\n",
    "plt.plot(mean30[-200:])\n",
    "plt.plot(mean60[-200:])\n",
    "plt.plot(mean90[-200:])\n",
    "plt.title('Kalman filter estimate of average')\n",
    "plt.legend(['Kalman Estimate', 'X', '30-day Moving Average', '60-day Moving Average','90-day Moving Average'])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The advantage of the Kalman filter is that we don't need to select a window length, so we run less risk of overfitting. \n",
    "\n",
    "<font color='blue'>We do open ourselves up to overfitting with some of the initialization parameters for the filter, but those are slightly easier to objectively define. \n",
    "\n",
    "<font color='blue'>There's no free lunch and we can't eliminate overfitting, but a Kalman Filter is more rigorous than a moving average and generally better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pricing data\n",
    "start = '2012-01-01'\n",
    "end = '2015-01-01'\n",
    "y = get_pricing('AMZN', fields='price', start_date=start, end_date=end)\n",
    "x = get_pricing('SPY', fields='price', start_date=start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and use colormap to indicate the date each point corresponds to\n",
    "cm = plt.get_cmap('jet')\n",
    "colors = np.linspace(0.1, 1, len(x))\n",
    "sc = plt.scatter(x, y, s=30, c=colors, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x[::len(x)//9].index])\n",
    "plt.xlabel('SPY')\n",
    "plt.ylabel('AMZN');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1e-3\n",
    "trans_cov = delta / (1 - delta) * np.eye(2) # How much random walk wiggles\n",
    "obs_mat = np.expand_dims(np.vstack([[x], [np.ones(len(x))]]).T, axis=1)\n",
    "\n",
    "kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                  initial_state_mean=[0,0],\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=obs_mat,\n",
    "                  observation_covariance=2,\n",
    "                  transition_covariance=trans_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the observations y to get running estimates and errors for the state parameters\n",
    "state_means, state_covs = kf.filter(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(2, sharex=True)\n",
    "axarr[0].plot(x.index, state_means[:,0], label='slope')\n",
    "axarr[0].legend()\n",
    "axarr[1].plot(x.index, state_means[:,1], label='intercept')\n",
    "axarr[1].legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points using colormap\n",
    "sc = plt.scatter(x, y, s=30, c=colors, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x[::len(x)//9].index])\n",
    "\n",
    "# Plot every fifth line\n",
    "step = 5\n",
    "xi = np.linspace(x.min()-5, x.max()+5, 2)\n",
    "colors_l = np.linspace(0.1, 1, len(state_means[::step]))\n",
    "for i, beta in enumerate(state_means[::step]):\n",
    "    plt.plot(xi, beta[0] * xi + beta[1], alpha=.2, lw=1, c=cm(colors_l[i]))\n",
    "    \n",
    "# Plot the OLS regression line\n",
    "plt.plot(xi, poly1d(np.polyfit(x, y, 1))(xi), '0.4')\n",
    "\n",
    "# Adjust axes for visibility\n",
    "plt.axis([125, 210, 150, 410])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('SPY')\n",
    "plt.ylabel('AMZN');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that although all of the state estimates take into account all previous observations, they fit the more recent data better than the older data. This allows the filter to <font color='blue'>adapt to structural changes in the data over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get returns from pricing data\n",
    "x_r = x.pct_change()[1:]\n",
    "y_r = y.pct_change()[1:]\n",
    "\n",
    "# Run Kalman filter on returns data\n",
    "delta_r = 1e-2\n",
    "trans_cov_r = delta_r / (1 - delta_r) * np.eye(2) # How much random walk wiggles\n",
    "obs_mat_r = np.expand_dims(np.vstack([[x_r], [np.ones(len(x_r))]]).T, axis=1)\n",
    "kf_r = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y_r is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                  initial_state_mean=[0,0],\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=obs_mat_r,\n",
    "                  observation_covariance=.01,\n",
    "                  transition_covariance=trans_cov_r)\n",
    "state_means_r, _ = kf_r.filter(y_r.values)\n",
    "\n",
    "# Plot data points using colormap\n",
    "colors_r = np.linspace(0.1, 1, len(x_r))\n",
    "sc = plt.scatter(x_r, y_r, s=30, c=colors_r, cmap=cm, edgecolor='k', alpha=0.7)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in x_r[::len(x_r)//9].index])\n",
    "\n",
    "# Plot every fifth line\n",
    "step = 5\n",
    "xi = np.linspace(x_r.min()-4, x_r.max()+4, 2)\n",
    "colors_l = np.linspace(0.1, 1, len(state_means_r[::step]))\n",
    "for i, beta in enumerate(state_means_r[::step]):\n",
    "    plt.plot(xi, beta[0] * xi + beta[1], alpha=.2, lw=1, c=cm(colors_l[i]))\n",
    "\n",
    "# Plot the OLS regression line\n",
    "plt.plot(xi, poly1d(np.polyfit(x_r, y_r, 1))(xi), '0.4')\n",
    "\n",
    "# Adjust axes for visibility\n",
    "plt.axis([-0.03,0.03,-0.11, 0.11])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('SPY returns')\n",
    "plt.ylabel('AMZN returns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>We can use a Kalman filter to model non-linear transition and observation functions, as well. \n",
    "\n",
    "<font color='blue'>For this purpose there exist extended and unscented Kalman filters, the latter of which is included in `pykalman`. \n",
    "\n",
    "<font color='blue'>These can even model situations where noise is not additive (for example, where noise is proportional to the size of the measurement). \n",
    "\n",
    "<font color='blue'>We can also specify non-Gaussian errors; this is useful in financial data, which tends to have heavy-tailed distributions.\n",
    "\n",
    "<font color='blue'>There are also algorithms for inferring some of the input parameters, such as the covariance matrices and initial state, from an initial set of data. This can be done with the `pykalman.em()` method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
