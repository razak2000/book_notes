chapter 2. Review of the Main Criteria

2.1 CRITERIA BASED ON LOGNORMAL DISTRIBUTION
2.1.1 Description of Lognormal Distribution
The effectiveness of option combinations evaluation is mainly determined by the accuracy of the underlying asset prices forecast. One of the possible ways to produce a forecast is building the probability distribution of the price. When applying this method we do not try to predict the future price exactly but estimate the probabilities of many possible outcomes. For the discrete price scale, the distribution is established by assigning probabilities to all outcomes. In the continuous case probability, density functions are used. We begin to create criteria for evaluation of option combinations with applying one of such functions: logarithmic normal distribution.

Consider a problem of making a forecast for a certain stock price in n days in the future. It is obvious that we cannot give a perfectly accurate estimate because the price depends on a huge number of interrelated factors unknown in advance. For example, the stock price that is $100 today can take any value in a month depending on the events that take place in the market. Of course, too low and too high values are unlikely whereas those close to the current price are more likely. Not trying to make an exact prediction, we assume that any value is possible and attempt to obtain the probability value for every price outcome. If the price is considered as a continuous real number, the probabilistic forecast of the future underlying asset price can be expressed as a probability density function f(B,x), where argument B denotes a certain underlying asset, and x is any possible price value.

Financial mathematics operates with series of underlying asset prices in consecutive time points t. For example, daily close prices C(t), t = 1, 2,... may be used to calculate relative changes

When price values are close, such relative changes (also called yields) are approximately equal to increments of natural logarithms of two adjacent prices:

In case of a continuous price series, the approximate equality turns into the exact one:

Price changes are affected by numerous factors. Their joint effect is unpredictable, which brings us to the key assumption: At any point of time t increments of price logarithms are random and independent of each other. The assumption of randomness implies that price changes cannot be described by any deterministic model but rather resemble white noise or Brownian motion. The assumption of independence implies that the given yield is not affected by the preceding yields and does not exert any influence on the consecutive yields. The central limit theorem of the probability theory states that the average of a large number of independent samples has the distribution that is close to normal (also called Gaussian). Hence another key assumption is made: Increments of price logarithms are normally distributed. This implies that the price logarithm itself is also a normally distributed random variable. Accordingly, the price distribution is called a logarithmically normal distribution or simply lognormal distribution.

Lognormal distribution is a standard price distribution model widely accepted by most economists. At the same time, its appropriateness for description of financial time series was frequently questioned, and this issue is widely debated on various scientific, theoretical, and practical occasions. Until now countless enthusiasts tried to find probability distributions that describe price dynamics more precisely. Literature is full of arguments and evidence stating that real prices have distributions, which differ substantially from the lognormal one. (“Fat tails,” excesses, and other “abnormalities” are often used as arguments.) Nevertheless, classical option pricing theory is based on lognormal distribution. This distribution is widely used and generally accepted because it has three indisputable advantages.

First, the lognormal distribution density function has a simple formula with a few parameters. Second, and this is the most important fact, normal distribution of price logarithms’ increments realizes the most general and hence the most robust approach exploiting the central limit theorem. Third, despite all criticism, numerous investigations proved that lognormal distribution quite adequately describes the distribution of real market prices.

Normal (Gaussian) distribution has two parameters: mean value a and variance σ2. The following formula sets up a relationship between the price x and the probability density value N(a,σ,x) corresponding to the future price outcome:

Lognormal distribution of a random variable is determined by the parameters of normal distribution of its natural logarithm:

where Mean is the expected price value at the future time t. There is a simple relationship between the parameters of lognormal distribution and the corresponding normal distribution:

2.1.2 Expected Profit on the Basis of Lognormal Distribution
Criterion Calculation Method
Calculation of the expected profit is based on the equation (1.6.1) proposed in Chapter 1, “General Presentation and Review of Criteria Properties,” as generalization for the universal criterion. Using the concept of the classical probability theory, mathematical expectation of profit of an option combination at a certain point of time is determined as follows:

(2.1.1)

where PF(B,S,x) is a payoff function of combination S with the underlying asset B;

LogN(Mean,σ,x) is a probability density function of lognormal distribution;

Mean, σ, and x are the parameters of lognormal distribution.

The integral formalized by the equation (2.1.1) represents the criterion that we call “expected profit on the basis of lognormal distribution.”

The payoff function PF(B,S,x) in equation 2.1.1 can be replaced by another function, for example, by the yield function expressed as the ratio of the payoff function to the investment amount normalized by the investment period. In this case the value calculated by equation 2.1.1 stands for another criterion: the “expected yield on the basis of lognormal distribution.” Similarly, we can formulate other “expected value” criteria based on the integration of different functions by lognormal distribution. Following the basic principle of option combinations evaluation by criteria, we adhere to the rule that combinations with higher expected profit are preferable to other alternatives.

Criterion Parameters
As it follows from equation 2.1.1, to obtain the value of expected profit, we have to express the forecast of the future stock price in the form of a probability density function. This requires determining the parameter values for the lognormal distribution. Application of this relatively simple distribution reduces the problem to the calculation of just two parameters: mathematical expectation of the underlying asset price at the point of time t and the variance of normal distribution of the underlying price logarithm.

The main advantage of option trading is the possibility to create market-neutral strategies that do not require predicting future price trend direction. Thus it is natural to assume that the mathematical expectation of the underlying asset price is equal to the current price as of the criterion calculation date. It means that we do not make any assumptions about the growth or fall of the underlying asset but consider the current price as the most probable estimate for the forecast date. The alternative approach implies assigning an expert value to this parameter. For example, if a fundamental analyst forecasts price growth (or fall), then a mathematical expectation, which is higher (or lower) than the current stock price, may be used to calculate the criterion. In Chapter 1 we discussed the possibility of developing forecasts on the basis of expert estimates combined with a statistical analysis. The “expected profit on the basis of lognormal distribution” can be a typical example of such combined criterion if lognormal distribution (built on the basis of historical prices) is combined with expert estimates of mathematical expectation of the underlying asset price.

The value of the second parameter—the variance σ2 of normal distribution of the stock price logarithm—can be taken as equal to the square of stock historical volatility. Although this characteristic is of great importance in the option world, the consensus on the precise manner of its estimation is far from being achieved. Apart from the classical model, there is a variety of elaborated formulae intended to calculate more precise values of historical volatility (Garman & Klass,1980; Parkinson, 1980, and so on). Depending on the chosen formula, the parameter value and, consequently, the criterion itself will change significantly. We dwell on the simplest case when historical volatility HV is calculated at a certain historical period as the mean-square deviation of logarithms of consecutive daily close prices ratios:

(2.1.2)

where t0 is the current time;

P is the period of historical volatility calculation (expressed in fractions of a year);

N is the number of close prices ratios used (the number of days preceding the current date).

Equation 2.1.2 is a simplified version of historical volatility modeling. However, our experience shows that its accuracy is sufficient for the purpose of criteria computation. We refer to the number of days preceding the current date (N) as the length of historical volatility calculation period. Its proper choice is a key moment in calculating this parameter because, as can be seen from equation 2.1.2, the variance value is extremely responsive to period length changes. Moreover, we can say that the true parameter that determines the practical effectiveness of the criterion is N. Rules of determining N are usually thoroughly protected intellectual property; they are discussed a lot but specific algorithms are always concealed. There is an opinion that most option trading specialists do not possess formalized algorithms for calculation of this parameter but rather rely on their intuition and experience. In any case, the existence of one unique and universal algorithm is most unlikely. There should be various rules for determination of N, and these rules should change depending on the option strategy in use, the forecast horizon, and the algorithm of underlying assets selection.

To illustrate the relationships between the “expected profit on the basis of lognormal distribution” criterion and its parameters, we constructed the option combination called proportional long strangle using the AAPL stock as the underlying asset. (A full combination description is given in the next example). Figure 2.1.1 demonstrates to what extent this criterion depends on values of lognormal distribution parameters (mathematical expectation of the underlying price [Mean] and the historical volatility calculation period length [N]). The criterion reaches its minimum when Mean is close to the current stock price ($94.68). This is due to the fact that long strangle is unprofitable when the price is not changing considerably. Conversely, Mean values that are higher or lower than the current price lead to criterion value growth. The influence of the second parameter is no less obvious: when the period used for the calculation of historical volatility is short, the criterion values are low, but when the period length increases, the criterion also grows (Figure 2.1.1). This example shows that the criterion value may turn out to be either negative or positive (and even rather high) depending on values of its parameters. The form of this relationship depends strongly on specific option strategy and underlying asset; furthermore, it can be changed in time even for the same {strategy × underlying asset} pair. Thus when selecting parameter values, it is necessary to analyze every situation thoroughly and to consider it in the context of the current time point.

Figure 2.1.1. Relationship between values of the “expected profit on the basis of lognormal distribution” criterion and two parameters of lognormal distribution: mathematical expectation of the underlying price (Mean) and the length of period used for calculation of historical volatility (N). The option strategy is “proportional long strangle.”

Criterion Calculation Example
The criterion value will be calculated for the “proportional long strangle” option strategy. On April 5, 2007, the close price of AAPL was $94.68. Options expiring on April 21, 2007, traded with the following ask prices: Call 90 — ask $5.2, Put 95 — ask $1.85. Consider the combination consisting of two long Put options and one long Call option.

To proceed with criteria calculation, we have to set up the parameters of lognormal distribution. We assume that mathematical expectation of the stock price at time t is equal to the current price Mean = 94.68 (according to the principle of market neutrality). Equation 2.1.2 is applied to calculate historical volatility on the basis of the 120-day history of close prices (N = 120). The obtained value is HV = 30.29%. To derive variance from the HV value, we have to apply the correction factor that would take into account the time period from the present time point until the forecast date for which we calculate the criterion value. This factor equals the square root of the ratio of the number of days until the forecast date to 365. Because in this example the criterion is calculated for the expiration day (which is the forecast date), the time left from the present time point until the expiration equals 15 days. Thus image.

Figure 2.1.2 presents the payoff function of the combination calculated for the expiration date (given that each option is bought at the ask price) and the probability density function of the lognormal distribution built with parameters equal to the values previously fixed. Integrating the product of the payoff function by the lognormal probability density function (equation 2.1.1), we obtain the expected profit of the combination at the time of options expiration: MeanLogNorm = 1.6052. What does this value mean in the context of combination evaluation? The criterion value is positive, which indicates potential combination profitability. However, we should not expect that exactly this profit will be received from the investment in this combination. The obtained criterion value rather represents the most probable result. If we could run a series of statistical experiments with many possible outcomes, the average profit of all outcomes would work for the criterion value. However, in reality only one outcome will occur. It means that application of criteria based on probability distributions is reasonable only when they are systematically used over and over again in real trading. This implies that application of the probability theory for valuation of options and their combinations requires prudent interpretation of results.

Figure 2.1.2. Payoff function corresponding to the “proportional long strangle” combination (see the full description in the text) and the probability density function of the lognormal distribution.

2.1.3 Profit Probability on the Basis of Lognormal Distribution

Criterion Calculation Method
Depending on the future underlying asset price, the payoff function of any combination may be either negative (which corresponds to the combination loss) or positive (which corresponds to profit). Moreover, the magnitude of possible profits and losses varies substantially between different option strategies. Thus long strangles and straddles have unlimited potential profit if the underlying asset price moves significantly but have limited loss potential if the price doesn’t change. On the contrary, short strangles and straddles are limited in their profit potential (they are profitable only if the underlying asset price does not change or changes just slightly) and have unlimited loss potential if the price jumps considerably.

The criterion expressing profit probability estimates the probability that at the time of options expiration (or any other forecast time point) a payoff function of a given combination will have positive value. In other words, this criterion estimates the probability that the combination will be profitable. (That is, profit values will exceed zero.) Whether the payoff function is positive or negative is determined by the price of the underlying asset at the forecast time. In the example discussed in the previous section, the payoff function is positive for all AAPL prices lower than $91.12 and higher than $98.92.

The “profit probability on the basis of lognormal distribution” criterion is calculated by integrating the product of the combination payoff function by the probability density function over the price range (or ranges) for which the payoff function is positive. Following the preceding notation (equation 2.1.1) the criterion can be formalized as:

(2.1.3)

where θ(y) is the theta-function with argument y = PF(B,S,x), which has the following values: θ(y) = 1, if y > 0, and θ(y) = 0 in other cases.

To calculate this criterion value we use the same two parameters as in the case of expected profit: mathematical expectation of the underlying stock price at time t and the variance of normal distribution of the stock price logarithm.

The sense of expression 2.1.3 is easy to realize in the discrete case when a finite price series {xt,t = t1,t2,...,tn} is considered. (These prices constitute a set of possible future outcomes.) In such case we get the set of probabilities image assigned to the corresponding price outcomes instead of the probability density function LogN(x). Price index i form two subsets: image, where the payoff function value is positive, and image, where the payoff function values are negative or equal to zero. Then our criterion turns into the sum of probabilities of elements forming the first subset:

(2.1.4)

Criterion Calculation Example
Consider the complex combination consisting of three Call options on the AAPL stock. The combination is created on April 5, 2007 with the following options: one long Call 80 (ask $17,5), two short Calls 95 (bid $7,3), two long Calls 110 (ask $2,25). All options expire on July 21, 2007. As in the previous example, the stock price at the combination creation date was $94.68. According to the market neutrality principle (when we do not forecast price movement direction), the parameter of mathematical expectation of the underlying stock price is assumed to be equal to the current price (Mean = 94.68). Historical volatility was estimated on 120-day price history. (N value is the same as in the previous example.) As in the previous example, HV amounts to 30.29%. There are 107 days left to expiration. Accordingly, multiplying the volatility by the correction factor, we get the variance value:

Figure 2.1.3 shows the payoff function PF(x) of the combination, the theta-function θ(PF(x)) and the probability density function of the lognormal distribution. The theta-function equals zero over the price range where the payoff function is negative and equals one for prices corresponding to the positive payoff function.

Figure 2.1.3. Payoff function of the combination consisting of three Call options (see the full description in the text), theta-function corresponding to this payoff function, and the probability density function of the lognormal distribution.

In this example there are two price ranges for which the payoff function is positive—from $87.43 to $102.40 and from $117.46 to infinity (Figure 2.1.3). Numerical integration according to formula 2.1.3 gives the criterion value of 0.45, which means that at the time of expiration this combination will be profitable with 45% probability. Of course, the same result will be obtained for the discrete case if equation 2.1.4 is applied. Selection of option combinations by maximizing this criterion minimizes the probability to choose unprofitable variants. Because this criterion does not estimate the magnitude of possible profit or loss values, it should be used not as an independent selection tool but jointly with other criteria expressing potential profit in an explicit form.

2.2 CRITERIA BASED ON EMPIRICAL DISTRIBUTION

2.2.1 Description of Empirical Distribution
Lognormal distribution describes the dynamics of market prices quite roughly. Settling its parameters Mean and σ we simplify information contained in historical price series due to averaging and application of other statistical procedures. On the other hand, it seems natural to assume that the future should resemble the past and to transfer the maximum information on price movements from the known past to the forecast future. This is the aim of constructing the empirical distribution.

By analogy with the lognormal distribution, we assume that price change is a random variable. The additional assumption—specific for the empirical distribution—is that probability distribution of price increments can be built on the basis of their past values. Within the framework of this approach, we collect history of price movements and derive the probabilities of future movements from the frequency of their past occurrence (Izraylevich and Tsudikman, 2009a).

Formally the empirical distribution is built in the following way. The current point of time is denoted by T0 and the future time point for which we build the empirical distribution of the underlying asset price is denoted by T. The difference between these two time points τ = T – T0, τ > 0 represents the forecast horizon. The length of the historical period used to build the distribution will be addressed as the historical horizon of the empirical distribution and will be denoted by L (L > τ). The larger the horizon, the more extensive statistics are at our disposal. However, old historical data may give wrong information about patterns and trends prevailing in the present market. Thus the selection of the best L value is a nontrivial task that is as important as finding optimal N in the case of lognormal distribution.

Having horizon values of τ and L fixed, we consider relative increments of prices p(t) = C(t + τ)/C(t) for all points of time t (t = T0 – L + 1, T0 – L + 2,..., T0 – τ). Thus we get L – τ observations of price increments. Multiplying the current price C(T0) by each of the relative increments we get a set of L – τ forecast price variants:

The obtained set of price values can be used to build a probability density function of the price distribution Empiric(x). This can be done on the basis of the histogram of L – τ forecast price values.

To illustrate the difference between lognormal and empirical distributions, we compare their density functions using INFY stock as an example. On April 5, 2007, the close price of this stock was $51.83. Its historical volatility calculated using equation 2.1.2 amounts to 28%. (The length of historical volatility calculation period N is 120 days.) Assuming that Mean parameter value is equal to the current stock price (according to the market neutrality principle), we obtain the probability density function of lognormal distribution (Figure 2.2.1). For empirical distribution the forecast horizon τ determined by the expiration date (April 21, 2007) equals 11 trading days. The historical horizon L is 250 trading days. Figure 2.2.1 shows that the average and maximum values of the empirical distribution are shifted to the right (toward higher price values) relative to the lognormal function. Empirical distribution also has a higher and narrower middle part and fatter left tail.

Figure 2.2.1. Probability density functions of the lognormal and empirical distributions of INFY stock.

The divergence between lognormal and empirical distributions usually decreases when the historical horizon of empirical distribution (L) increases. Figure 2.2.2 shows the lognormal and two empirical distributions built for NRG stock on April 5, 2007. The forecast horizon corresponds to the nearest expiration date of April 21, 2007. Lognormal distribution is based on historical volatility of 22.86% (N = 120) and the current stock price of $73.88. The probability density functions of empirical distribution are based on 120- and 500-day historical horizons. It is clear from Figure 2.2.2 that the shorter the historical horizon, the more peculiar the shape of the empirical distribution and the stronger its difference from lognormal distribution. The shift of empirical distributions to the right relative to the lognormal distribution reflects the stock price uptrend. Unlike lognormal distribution, empirical distribution reflects past trends and strong price movements. Figure 2.2.2 illustrates that the selection of values for the “historical horizon” parameter L strongly influences the shape of empirical distribution. Consequently, L exerts a great influence on calculation of the criteria based on this distribution.

Figure 2.2.2. Probability density functions of the lognormal and two empirical distributions of the NRG stock. Empirical distributions are built with 120- and 500-day historical horizons.

2.2.2 Expected Profit on the Basis of Empirical Distribution
Criterion Calculation Method
The main principle applied to the calculation of this criterion is similar to that of the criteria based on lognormal distribution. The “expected profit on the basis of empirical distribution” represents the integral of the combination payoff function taken over the probability density function of empirical distribution:

(2.2.1)

where PF(B,S,x) is a payoff function of combination S with underlying asset B;

Empiric(x)dx is the probability density function of empirical distribution.

Equation 2.2.1 represents the formalized definition of this criterion. However, for the practical purpose of option valuation, it can be estimated easier by direct application of the set of forecast prices image (see the previous section). The mathematical expectation of the underlying price at the forecast time is calculated as follows:

and the expected profit on the basis of empirical distribution is

(2.2.2)

This expression provides a simple computational procedure to find the criterion value.

According to the classification introduced in Chapter 1, this criterion is obviously universal and forecasting. Besides, it possesses an additional important feature. Calculating the criterion according to formula 2.2.2 means that its value is the average of L – t values of the payoff function that is calculated using forecast underlying asset prices. This implies that in addition to the average we can calculate another characteristic expressing variability of payoff function values (either standard deviation or standard error). The ratio of the average to the variability allows the creation of a new criterion containing important additional information. This derivative criterion, and the original one, is universal, but it is not forecasting because it is an abstract indicator that does not refer to any real characteristic.

Criterion Parameters
In contrast to the lognormal distribution model that has two parameters, empirical distribution possesses only one important parameter: the history horizon. The second parameter—the forecast horizon—is determined objectively by selecting the future date for which the criterion is calculated. It is widely known that selection of the parameter’s values is strongly influenced by subjective factors. Hence the more parameters included in the criterion model, the more it is affected by such unreliable factors. Besides, the large number of optimized parameters increases the risk of overoptimization (overadjustment to past data also referred to as curve fitting). Overoptimization means that trading systems showing impressive performance in back-testing experiments become unprofitable in real trading. Therefore, the fact that the empirical distribution has only one important parameter represents its indisputable advantage over the lognormal one.

On the other hand, the fact that parameter L is the only one requires even more prudence in selecting its value. While in a multiparametric model some inaccuracy in optimization of one of the parameters can be offset by successful optimization of the others, in the case of one-parameter model any inaccuracy may become fatal.

The horizon of history used to build the empirical distribution influences the criterion value considerably. Moreover, mathematical expectation of profit may turn out to be either positive or negative depending on applied L values. This statement can be illustrated with the following example. A short strangle consisting of options on the YHOO stock is evaluated by “expected profit on the basis of empirical distribution” criterion. In section 2.2.4 we describe in detail the structure of this combination and the algorithm of criterion calculation (for L = 90). Here to illustrate the extent of the influence exerted by L on the criterion output, we calculate MeanEmpiric(B,S) values for all L from 20 to 90.

The relationship between criterion and L is shown in Figure 2.2.3. Application of long history horizons (above 40 days) results in negative criterion values. Reducing the horizon to around 30 days leads the criterion to the positive area. However, further decrease of L value brings about the criterion fall once again. Figure 2.2.3 shows that the criterion may be either negative or positive depending on the parameter value used in the calculation. It means that for some L values the combination can be deemed potentially profitable and vice versa for other L values. This example vividly illustrates the importance of scrupulous analysis of all factors influencing the selection of the history horizon used for criteria that are based on empirical distribution.

Figure 2.2.3. Relationship between the “expected profit on the basis of empirical distribution” criterion and the “horizon of history” (L) parameter for the short strangle combination created for the YHOO stock.

To complete the picture we should make a note about the second parameter of the empirical distribution: the forecast horizon τ. The name of this parameter indicates that its value is automatically defined at the point of fixing the future date for which the criterion is calculated. Despite this, nothing (except logic) prevents us from assigning any whole number from 1 to L – τ to this parameter. Is there a sense in using the “horizon of forecast” value other than the real forecast horizon? Yes, there is! It is commonly known that the price changes more over longer time periods, that is, there is a straight relationship between absolute price changes and the length of time interval. It means that by increasing the horizon of forecast we can artificially raise the potential of possible future price movements and vice versa. (Remember that the real forecast horizon remains the same; only the parameter value changes.)

Is there any practical reason to modify the potential of price movements? Let us suppose that our criterion is applied to a certain combination built according to the short strangle strategy. This strategy implies large losses when the price change is substantial. Therefore, if we prefer to be more conservative in calculating the criterion, we can increase the parameter value and thus make the amplitude of potential price movement a bit higher. And vice versa, if we prefer to take a more aggressive position, we can set the parameter value lower, which will lead to underestimation of the possible price change. Thus, control over the “horizon of forecast” parameter represents an efficient tool of adjusting the criterion to the individual risk profile of an investor.

2.2.3 Profit Probability on the Basis of Empirical Distribution
As in the case of lognormal distribution, this criterion estimates the probability that at the specified future time point a profit value of a given combination will have positive value. For empirical distribution this criterion is formalized as follows:

(2.2.3)

where 1(y) is the theta-function with argument y = PF(B,S,x) which takes the following values: 1(y) = 1, if y > 0, and 1(y) = 0 in other cases.

In our simplified calculating scheme (when a finite series of discrete prices is considered), this criterion can be calculated as follows:

(2.2.4)

2.2.4 Simplified Calculation Algorithm
Several different techniques can be used to build empirical distribution and to compute criteria corresponding to it. Here we propose the method based on the simplified calculation procedure that operates on a finite series of discrete underlying prices (equations 2.2.2 and 2.2.4). The algorithm will be illustrated with calculation of two criteria: expected profit and profit probability on the basis of empirical distribution. The short strangle strategy applied to the YHOO stock will be used as an example. The date of position opening is May 30, 2007; values of both criteria will be calculated for the options expiration date (June 15, 2007). The combination consists of one short Call option with strike 30 sold at bid price $0.3 and one short Put option with strike 27.5 sold at bid $0.25. The close price of the stock on the date of combination creation was $28.38.

The horizon of history for the empirical distribution will be L = 90 days. The horizon of forecast will be τ = 16, which corresponds to the number of days until expiration. Figure 2.2.4 depicts the payoff function of our combination and the probability density function of empirical distribution. The lognormal probability density function is also shown on this figure to allow comparison between two distributions. Lognormal distribution was built with 120-day historical volatility (28.73%). Empirical distribution is shifted toward higher price values relative to the lognormal distribution that reflects the prevalence of uptrends in historical data used to build the empirical distribution. It is also notable that the empirical distribution has two local peaks and none of them reaches the maximum of the lognormal distribution.

Figure 2.2.4. Probability density functions of the empirical and lognormal distributions built for the YHOO stock and the payoff function of the short strangle strategy.

To calculate criteria values we list 90 close prices in historical order (the first column of Table 2.2.1). The second column contains close price ratios pj calculated according to the horizon of forecast (16 days). For example, the first pj value is the ratio of the 17th day close price to the 1st day close price: 26.85 / 26.34 = 1.02. The third column of Table 2.2.1 contains estimates of the future stock price (forecast for 16 days in future from the corresponding close price). Values of Cjemp are obtained by multiplying pj by the current stock price (for example, the first Cjemp value is calculated as follows: 28.38 × 1.02 = 28.93). The fourth column contains values of the combination payoff function PFj estimated for the expiration time. The fifth column contains the theta-function of PFj which is 1 for positive PFj and 0 for other values.

Table 2.2.1. Data Required for Calculation of Expected Profit and Profit Probability Criteria on the Basis of Empirical Distribution

Expected profit MeanEmpiric(B,S) and profit probability ProbEmpiric(B,S) on the basis of empirical distribution are calculated according to equations 2.2.2 and 2.2.4 respectively. Actually values of these criteria are obtained by averaging the fourth and the fifth columns of Table 2.2.1 respectively: MeanEmpiric(B,S) = –0.27 and ProbEmpiric(B,S) = 0.53. These values suggest that the combination evaluated in this example is hardly perspective according to the criteria based on empirical distribution. However, we should not forget that the same criterion MeanEmpiric(B,S) has valuated the same combination as potentially profitable when its parameter L was valued within the range of 30 to 40 days (section 2.2.2, Figure 2.2.3). This fact points once again at the crucial importance of the thorough criteria parameterization and at the impact of this procedure on valuation of option combinations.

In the previously mentioned example, criteria values are calculated for the expiration date. However, this should not always be the case. If an investor does not intend to hold a position until expiration, he can calculate criteria values for any intermediate date (depending on the prospective position holding period). This requires two modifications of the algorithm previously described. Firstly, we have to adjust the horizon of forecast according to the period of position holding (number of days from the position opening until the intermediate date). In our example, if we are interested in calculating criteria values not for the expiration date (June 15) but for June 10, the horizon of forecast will be 11 days rather than 16 (the calculation of close prices ratio pj will change accordingly). Secondly, the payoff function values should be calculated not for the expiration date but for the intermediate one. Here we face another obstacle: Although the calculation of payoff values for the expiration date is unambiguously defined, their estimation for any intermediate date is possible only by the application of option pricing models. Because all models—including the most sophisticated ones—have drawbacks arising from their basic assumptions, values of criteria calculated at intermediate dates may inherit various inaccuracies.

2.2.5 Modifications of Empirical Distribution
At first glance empirical distribution should produce better criteria than any other distribution because it is based on the price fluctuations that have actually occurred recently. (We have mentioned that empirical distribution can even reflect some past price trends.) However, the pitfall is right there. Market statistics is usually not stationary. The future does not always repeat the past. Strong trends and narrow trade ranges alternate unpredictably, and volatile periods come to the place of tranquility irregularly without any distinguishable periodicity. That is why empirical distribution as a plain combination of past observations is not always the best way to create a probabilistic forecast. We developed several techniques to modify empirical distribution in the manner that makes it possible to moderate its drawbacks while maintaining its merits. Two of them are described here.

Weight Function as a Substitute for the Horizon of History Parameter
One of the modification methods is based on the introduction of weight coefficients for past price movements. Higher weights are attributed to recent observations, whereas old data get relatively low weights. Such weighting permits to differentiate the influence of observations depending on their time of occurrence. Introduction of the weight coefficient modifies the equations 2.2.2 and 2.2.4 as follows:

(2.2.5)

(2.2.6)

where image is a series of increasing positive weight coefficients.

Applying formulae 2.2.5 and 2.2.6 we can calculate criteria values so that recent price changes exert stronger influence on the final result than more distant ones. Implementation of weighting procedure leads to the gradual “forgetting” of old data. The function a(j), which sets the weights {aj}can be of any form; it can be linear (with weight coefficients decreasing in time evenly), exponential, and so on. Selection of a specific formula for this function can substitute the optimization of such important empirical distribution parameter as the horizon of history. It can be achieved in the following way: The horizon of history is fixed at its maximum (for example, more than several years or full historical database available). In this situation optimization of L is replaced by the selection of the way of “forgetting past data” that is done by choosing the appropriate equation for a(j) function.

At first glance it seems that applying formulae 2.2.5 and 2.2.6 just replaces one complicated problem (L optimization) by another (selecting the formula for a(j) function). Actually it is not true. Because there are no objective criteria to optimize L, we are obliged to use the past data fitting that can turn to be just overoptimization. On the other hand, deliberate selection of a(j) function can objectively reflect the investor’s perception of market patterns and cycles.

Symmetrization of Empirical Distribution

The second method of empirical distribution modification is based on its symmetrization. This procedure is performed through doubling the observations sample by adding to each p(t) = C(t + τ)/C(t) its inverse value p–1(t) = C(t)/C(t + τ). This operation enriches the initial information used to calculate criteria by incorporating not only recorded past movements into the final distribution but their inverse values as well. Such modification allows for realizing two plausible assumptions. Firstly, it rejects the hypothesis of continuing market trends (empirical distributions reflect trends that prevailed in the past). All trends sooner or later turn around or enter the correction phase. There are no reliable instruments to estimate the probability of a trend continuation or turn. Secondly, future inverse price movements are likely to have characteristics similar to past movements.

Figure 2.2.5 demonstrates the effect of empirical distribution symmetrization. It depicts three distributions for the AMAT stock as of June 1, 2007, when its price was $19.34. All distributions are calculated as probabilistic forecasts for the nearest expiration date (June 16, 2007). Empirical distributions are based on a 120-day history. Historical volatility used for construction of lognormal distribution (HV=23.28%) was estimated on the same history length. The procedure of symmetrization does not only smooth the empirical distribution probability density function, but also eliminates its asymmetry while maintaining individual features and differences with lognormal distribution (Figure 2.2.5).

Figure 2.2.5. Probability density functions of lognormal, empirical, and symmetrized empirical distributions built for AMAT stock.

Application of the symmetrization procedure produces two new criteria similar to those obtained using equations 2.2.1 and 2.2.2. The criterion expressing profit expected on the basis of symmetrized empirical distribution is formalized as follows:

(2.2.7)

and the criterion expressing profit probability is calculated as:

(2.2.8)

where SymEmpiric(x) is the probability density function of the symmetrized empirical distribution.

Formulae for simplified criteria calculation are analogous to expressions 2.2.2 and 2.2.4. Applying them and using the previously described algorithm we can estimate the criteria based on the symmetrized empirical distribution. To illustrate the procedure of simplified criteria calculation, we use the same option combination as in the example described in section 2.2.4. First, we add the inverse value to each pj value shown in Table 2.2.1. For example, pj-1 = 1/1.02 = 0.98 is added to pj = 1.02. Then we compute all forecast prices and payoff function values related to them. In the previous example for pj-1 = 0.98, we obtained the forecast price Cjemp = 0.98 × 28.38 = 27.81 and the payoff function related to it PFj = 0.55. Averaging 148 values of the payoff function (74 values from Table 2.2.1 plus 74 new values based on inversed forecasts) and 148 values of the theta-function, we get the following criteria values: MeanSymEmpiric(B,S) = –0.37 and ProbSymEmpiric(B,S) = 0.45. In this particular case the symmetrized distribution gives worse values for both criteria compared with simple empirical distribution (section 2.2.4). In other circumstances—for other strategies, underlying assets or even with the same strategy and underlying assets, but at a different time point—it can be vice versa. Extensive statistical studies (not presented here) suggest that two criteria do not duplicate but rather supplement each other.

2.3 CRITERIA BASED ON THE RATIO OF EXPECTED PROFIT TO LOSS
2.3.1 Basic Concept and Criteria Calculation Method
In previous sections we described two main types of universal forecasting criteria based on probability distributions. The criteria forecasting future profit express it in terms of mathematical expectations on the basis of a certain distribution. Similarly, the criteria forecasting profit probability express the probability of positive returns estimated on the basis of a certain distribution. Next we introduce new universal, but nonforecasting, criteria that combine the advantages of these indicators and possess additional useful features.

The argument values of any payoff function (that is, the set of possible future underlying asset prices) break up into two nonoverlapping subsets: profit and loss areas. The first area represents price values for which the payoff function is positive, and the second area includes prices for which the payoff function becomes negative. If at the expiration date (or any other time for which we are calculating criteria values) the underlying price has a value falling within the first subset, then the combination will be profitable; otherwise it will not earn any profit. The subset of price values where the payoff function is positive is denoted by I+ = {x : PF(B,S,x) > 0}. Correspondingly the subset of price values where the payoff function is negative is denoted by I– = {x : PF(B,S,x) < 0}. Two integrals of the payoff function over profit P(B,S) and loss L(B,S) areas can be calculated separately for each subset:

(2.3.1)

(2.3.2)

where PF(B,S,x) is the payoff function related to the combination S and the underlying asset B; x is the underlying asset price; f(B,x) is a probability density function estimated for a certain future date. The difference between these two integrals P(B,S) – L(B,S) is nothing else but our “expected profit on the basis of f(B,x) distribution” criterion. Its value can be the same under different P(B,S) and L(B,S) values (for example, if both integrals are increased or decreased by the same value).

Consider two option combinations S1 and S2 with the same expected profit values P(B1,S1) – L(B1,S1) = P(B2,S2) – L(B2,S2), but P(B1,S1) > P(B2,S2) and L(B1,S1) > L(B2,S2). Suppose that we estimate two trading systems: The first one opens positions for the combinations having characteristics similar to that of S1, whereas the second system opens positions for the combinations similar to S2. The equality of expected profit values means that in case of multiple trades both trading systems will generate the same profit. However, the first system is more volatile because it is characterized by higher potential profits and losses values. Thus, both trading strategies approach the same target but in different manners. Big losses of the first system can cause irretrievable capital losses, and when the funds allocated to trading are limited, it can result in bankruptcy before the system can win back. (The details of capital allocation deserve a separate discussion that is given elsewhere.) Similarly, target profitability of the first system can remain unachieved if the system is limited by the maximum drawdown parameter that stops trading if a certain threshold value is reached. It means that given the same expected profit combination, S1 is more risky than combination S2. By maximizing the following function, we can maximize potential profit while minimizing possible losses (that is, risk):

(2.3.3)

PL_factor(B,S) is a “ratio of expected profit to loss” criterion with values ranging from –1 to 1. Minimum value –1 means that the combination is unprofitable for all possible underlying asset prices; maximum value +1 means that the combination is profitable for all underlying prices. (Both extremes are unrealistic.)

According to our classification (Chapter 1), PL_factor(B,S) is a universal nonforecasting criterion. It can be applied to all option strategies with any payoff functions. Actually, it represents a whole set of criteria because every probabilities distribution f(B,x) generates its own criterion. Thus it is possible to use several PL_factor(B,S) criteria based on different distributions (lognormal, empirical, symmetrized empirical, or any other) simultaneously in the multicriteria selection of option combinations.

The evident advantages of this criterion are (1) its abstract nature (it is not expressed in any particular units, such as percentage or currency, as is the case with criteria estimating expected profits and probabilities) and (2) the uniform scaling of its values which lie in the strictly defined interval. (The latter feature allows easy processing and manipulation of criterion values.) Besides, applying the ratio of expected profit to loss allows comparison of option combinations by their inner structure regardless of the investment amount and margin requirements. Due to the specific construction of this criterion (formula 2.3.3), the form of profit expression and its normalization become unimportant. Calculation of criteria that estimate mathematical expectations in terms of relative yields require normalization by margin requirements and the time of position holding. However, any normalization executed via dividing profits and losses by investments and time would be offset because it has to be performed both in the numerator and the denominator (see expression 2.3.3). Thus the PL_factor(B,S) criterion is neutral to such operations.

Because the fluctuations of the underlying asset price during the life of the combination constantly change margin requirements, the exact investment amount is hard to identify. Normalization by time generates some additional problems arising from uncertainty about the investment period. That is why the absence of such normalizations makes this criterion more reliable and universal for systematic evaluation of option combinations.

2.3.2 Criteria Calculation Example
Consider the “butterfly” combination for the YHOO stock. Its close price on June 25, 2007, was $27.64. The combination consists of the following options expiring on July 21, 2007: one long Call 25 (ask price $2.95); two short Calls 27.5 (bid price $1.05); one long Call 30 (ask price $0.35).

Figure 2.3.1 shows the payoff function of this combination (built for the expiration date) and probability density functions of lognormal (28.6% volatility) and empirical (250-day horizon of history) distribution. Note that the shapes of two distributions differ substantially. The empirical distribution has a much higher peak (meaning that it forecasts a frequent occurrence of small price movements) and its tails are thin (implying that strong price changes are considered as relatively rare events). To the contrary, the lognormal distribution is characterized by a rather flat function predicting a more common happening of moderate and strong price movements and estimating small price fluctuations as infrequent.

Figure 2.3.1. Probability density functions of the empirical and lognormal distributions built for the YHOO stock and the payoff function of the butterfly strategy.

Simple numerical point-by-point integration (100 points were used in this calculation) gives the following values:

for lognormal distribution:

P(YHOO, Butterfly) = 0.3113;

L(YHOO, Butterfly) = 0.4402;

PL_factor(YHOO, Butterfly) = –0.1715;

for empirical distribution:

P(YHOO, Butterfly) = 0.7623;

L(YHOO, Butterfly) = 0.0374;

PL_factor(YHOO, Butterfly) = 0.9064.

Note that the ratio of expected profit to loss calculated on the basis of lognormal distribution is negative, which means that this combination is estimated by this criterion as potentially unprofitable. At the same time the criterion calculated on the basis of empirical distribution identifies the same combination as profitable. Such “pluralism” enriches the information obtained while evaluating option combinations by criteria. To make a final investment decision, we just have to decide which distribution is better in forecasting future price movements.

2.4 CRITERIA BASED ON EXPERT DISTRIBUTION
2.4.1 Basic Concept and Criteria Calculation Method
Up to here we have been developing criteria based on probabilistic scenarios of future underlying asset price fluctuations. Past data was the main source of information. Applying this approach we built different probability density functions forecasting price distributions at different future time points. Lognormal and empirical distributions described in previous sections represent two typical examples of this method. However, relying solely on historical data is fraught with risks of omitting details that might turn out to be essential for future events forecasting. Furthermore, setting the parameters of lognormal distribution—its mean and variance—implies that we assume market neutrality and specific volatility features. (These assumptions may turn out to be incorrect.) The form of empirical distribution also depends on peculiarities inherent to its generation algorithm. An important feature is common for all probability distributions based on historical data: Although the algorithms used for construction and application of such distributions can be easily formalized, the reliability of their forecasts frequently raises many reasonable doubts.

Criteria discussed in this section are based on an absolutely different approach. As it follows from the heading, creating such criteria implies engaging specialists to evaluate qualities of option combinations on the basis of fundamental analysis of their underlying assets. Professional opinions of experts must meet two main requirements. Firstly, they should not be based on past price data but only on fundamental characteristics of an underlying asset. (Otherwise we get a kind of empirical or similar distribution rather than the expert one.) Secondly, the expert opinion must be expressed in strictly formalized numerical form. This means that an expert must not only indicate the direction of anticipated price movement but also specify more and less probable future price ranges. The best way to formalize the expert forecast is to build the probability density functions—like we did for other criteria—with the only difference that the probabilities of different outcomes are estimated in this case on the basis of expert opinions and not of past events.

Formalizing the expert forecast as a probability density function is an extremely complicated task. However, it can be successfully solved if a specialist is provided with a proper instrument—we call it the interactive probability scenario builder. Scenario builder is a software program consisting of several essential modules.

• The first and the main one represents a mathematical structure intended to calculate different probability distributions with parameter values fixed by the expert.

• The second module combines the set of separate distributions created in the first module into a unified probability density function.

• The third module calculates criteria on the basis of the combined density function produced in the second module.

Application of the interactive probability scenario builder software reduces the expert’s task to consecutive execution of the following steps:

From the variety of basic standard distributions, select the most appropriate ones to create the combined probability density function.
Determine optimal values for parameters of distributions selected at the first step.
Determine criteria that can reflect the forecast of future events most adequately and calculate their values on the basis of the unified density function.
The main and necessary elements of the first module are uniform, lognormal, empirical, symmetrized empirical, exponential distributions, and at least one distribution with fat tails. Although other distributions may also be included in this basic set, practice shows that these previously mentioned main elements represent the sufficient kit required to structure a forecast of any complexity. Two features of any distribution are of particular interest for the expert: its position relative to the price axis and the spread. Position is a coordinate of the most typical distribution point, that is, the point where the density function reaches its maximum (in statistics it is called mode). In the case of nonexpert criteria, the position is often taken as equal to the current underlying asset price. Here it is not necessary because this is the parameter that most fully reflects the specialist’s view on the future price evolution. Analogously, the spread is not necessarily derived from historical volatility. The expert must deeply understand the nature of these distribution parameters—position and spread—to manipulate them freely to select their optimal values. The change of these parameters in the probability scenario builder software should be easy to make by a simple dragging operation or by inputting respective values.

2.4.2 Set of Standard Distributions
Every element of the first module of the interactive probability scenario builder should be a simple standard distribution with the minimum number of parameters. Its interpretation must be obvious for an expert and realize some simple idea of a future scenario expressed in the probabilistic form. Here we dwell on some of the basic elements of the first module.

Uniform Distribution

This distribution has the following density function:

Here Cmin and Cmax are the minimum and maximum possible values of the underlying asset price. Applying uniform distribution the expert claims that at some future time T the price will be at any point of the [Cmin,Cmax] range with equal probability and will not go beyond it. Mathematical expectation of the future price value is image. The parameters that must be fixed by the expert are Cmin and Cmax. The middle of the [Cmin,Cmax] segment represents the mathematical expectation. The spread of the uniform distribution is automatically determined by the length of the segment Cmax – Cmin..

Figure 2.4.1 shows the density function of uniform distribution for Cmin = 30 and Cmax = 60. This distribution forecasts that the price will take any value between $30 and $60 with equal probability and under no circumstances will go beyond this range. Such expert estimates can follow from fundamental analysis of threshold oversold and overbought levels of a stock. It is important to emphasize that we do not discuss the final forecast, but rather one of the basic elements required to compile it.

Figure 2.4.1. Probability density function of the uniform distribution built for Cmin = 30 and Cmax = 60.

Lognormal Distribution

This distribution is the most popular one in the option pricing theory. The mathematical background of its density function was described in section 2.1.1. The most convenient way to handle the lognormal distribution is to manipulate with the mathematical expectation of the underlying asset price (which is the average price weighted by probability) and with its variance (expressed through volatility). The values of these parameters, which are available from numerous sources of market information, are continually analyzed and interpreted by experts.

Figure 2.4.2 shows two probability density functions of lognormal distribution for a weighted-average price of $50 and a 40% volatility, and for a weighted-average price of $70 and a 50% volatility. Because the lognormal distribution is asymmetric, its peak (formally speaking—mode) corresponding to the most probable price value does not coincide with the mathematical expectation. In Figure 2.4.2 the most probable price (mode) of the function with a weighted-average price of $70 is around $50, and for the function with a weighted-average price of $50, the peak is at $40. Thereby, the expert gets an additional parameter—the most probable price—to handle the lognormal distribution.

Figure 2.4.2. Probability density functions of lognormal distribution built for different parameters of mathematical expectation and volatility.

How could this additional third parameter be used? To answer this question we have to discuss the general scheme of handling the lognormal distribution by experts.

An expert who uses lognormal distribution as one of the basic elements forming a unified probability density function assumes that fluctuations of the underlying asset price represent a geometrical Brownian motion with a certain mathematical expectation value at moment T and variance. However, this assumption follows solely from the mathematical form of lognormal distribution. In reality, the expert, as a fundamental analyst, considers price movement not as a random Brownian process but as a movement toward a certain target. He expects that this target will sooner or later be achieved (or, at least, approached) by the pseudo-chaotically fluctuating price. To proceed with the Brownian motion analogy, we can say that the analyst should think of the price as of a charged Brownian particle that moves not in the neutral environment but in the electrostatic field. In this situation the expert has to estimate the intensity of the electrostatic field (which determines the speed of the price—“particle” on the way to its target) and to locate the position of the electrode with the opposite charge (which determines the direction of the price—“particle”). The theoretically straight path of this Brownian particle is modified by the unpredictable impact of chaotically moving surrounding molecules which—coming back from this physical allegory to the reality of the financial world—can be compared to the influence of economic and corporate news entering the market unpredictably and irregularly. This philosophy should be used by a fundamental analyst when applying the lognormal distribution to market analysis and forecasting.

Based on his vision of future market events, an expert has to determine values for lognormal distribution parameters. Namely, he must predict the average future price and its variance. The former is not complicated, if the analyst has a deep understanding of the fundamental properties of the considered underlying asset. On the other hand, determining the variance may become an almost unrealizable task if the analytical tools available to the expert are strictly limited to the instruments of fundamental analysis. Remember that the expert should base his forecasts only on the fundamental characteristics of an underlying asset whereas an estimate of the variance is hard to derive from the information based on economical indicators. There are several ways to solve this issue. Variance can be forecast on the basis of past volatility. However, in this case we get hybrid criteria that combine both approaches—expert forecast (determining the average future price) and approach based on past data analysis (determining variance). Alternatively, we can obtain the variance value from option market prices by deriving their implied volatility. However, in this case instead of forming our own view on underlying volatility, we are forced to rely on the opinion of the broad market. Below we introduce the third method: using the most probable price (mode) as an additional parameter replacing variance.

To use lognormal distribution, the expert has to construct the probability density function similar to that presented in Figure 2.4.2. Such functions are defined by fixing two parameters: mean and variance. If the expert cannot define the variance, he can fix the values of mean and mode (the most probable price) and then select the variance so that the final function corresponds to these two parameters. In this way we obtain the “implied variance” value allowing construction of the lognormal distribution probability density function. How should the expert assign different values to these close parameters, the mean, and the mode? We propose the following sequence of steps.

The expert defines the first parameter: the mode. This is easy because the mode, which is the most probable price, coincides with the future price forecast by the expert’s fundamental analysis.
Then the expert assigns probabilities to other price outcomes. To do this, he chooses some reasonable (not too wide) price range, and each price from within this range (with a certain step) is given a probability of its realization for the time of forecast. The sum of all assigned probabilities must be equal to one.
These probabilities are multiplied by the corresponding prices, the results are summed up, and the sum is divided by the number of items.
This operation provides us with a value of the second parameter: the mean (which is the mathematical expectation of future price value). The variance value, corresponding to the values of these two parameters, is then obtained iteratively. Further density function creation is obvious.

Exponential Distribution
This distribution plays an important role in the basic set of standard distributions (the first module of the interactive probability scenario builder). It is very useful for forecasting the outcomes of corporate upcoming events. Consider the situation when the FDA (Food and Drug Administration) decision on some drug developed by a biotechnological company is expected on a certain date. According to the expert’s opinion, if the FDA approves the commercialization of this drug, the stock price will rise above a certain threshold level. The higher the extent of price excess over the threshold level, the lower its probability. In case of the opposite FDA decision—prohibition of drug commercialization—the stock price will plunge and break another threshold level. As a result, the price will be lower than the predetermined level. And again the lower the price is relative to the threshold level, the lower the probability of such outcome. The most convenient way to express the forecast of the upcoming event is to combine two exponential distributions (one for each variant of the FDA decision).

The probability density function of exponential distribution is defined as follows:

where μ is the mathematical expectation of the exponential distribution (its variance equals to µ2).

Consider the situation when the expert fixes the following values: xu = 60 as the upper threshold level (which corresponds to the positive outcome of the forecast corporate event, such as drug approval in our example) and xd = 45 as the lower threshold level (corresponding to the negative outcome of the forecast corporate event, such as drug refusal in our example). The distribution describing the positive outcome (price moving up) has the following form:

and the distribution describing the negative outcome (price moving down) has the following form:

The variance parameters σu, σd should also be selected by the expert individually for each case. These parameters define the rate of decrease of the probability corresponding to the prices upper (positive outcome) or lower (negative outcome) than fixed threshold levels. Suppose that the expert sets σu = 10 for the exponential distribution describing the up movement of the price and σd = 5 for the down movement. Then the probability density functions for breaking the $60 threshold level by the price moving up and the $45 threshold level by the price moving down will have the shapes shown on Figure 2.4.3.

Figure 2.4.3. Probability density functions of exponential distribution built for two cases: price breaking upper threshold level (xu = 60, σu = 10) and price breaking lower threshold level (xd = 45, σd = 5).

The three distribution types described here (uniform, lognormal, and exponential) form quite a representative basic set. To enhance the expert’s flexibility in the process of creating the final combined probability density function, this set should be enlarged with more complicated distributions. It would be useful to add two main forms of empirical distribution and several distributions simulating “fat tails.”

2.4.3 Combining Separate Standard Distributions into a Unified Probability Density Function
By choosing a certain distribution, the expert fixes a model intended to describe a certain variant of the possible future market developments. For a high-quality forecast the expert should take into consideration many potentially possible alternatives. This concept may be illustrated by our example of a biotechnological company anticipating an approval of its new drug. By now we have discussed only two scenarios: its approval and disapproval. Actually, there are at least two other possible outcomes. The first possibility is that the decision of the FDA will be postponed for an uncertain period of time. The second possibility corresponds to taking an interim uncertain decision, neither approval nor refusal (for example, requirement to perform additional clinical tests of the drug). Considering the situation in this way implies that price breakings of the upper and lower thresholds (modeled by means of exponential distributions) represent just two separate components of the final unified forecast that has to be made. To construct it, we have to select distributions adequately describing two additional possible outcomes. For the case of the postponed decision (when there are no events in the nearest future), we can use lognormal distribution with parameters defined by application of standard fundamental analysis methods. The second case (interim decision) is much harder to simulate. Market reactions to the decisions of such kind are unpredictable and range from price soaring to a sharp fall (depending on the details of information). The lack of any reaction or just a minor reaction is also possible. Such outcomes can be described by uniform distribution with a sufficiently large price range.

We have selected distributions for all the four possible outcomes. The next step is to define the probability of each of these outcomes. The expert should make an estimate of these probabilities in the form of the weight coefficient assigned to each distribution; the greater this weight, the more probable the outcome. For example, if the expert thinks that breaking the lower threshold level is twice as probable as breaking the upper threshold level, he can assign the weight coefficient 2 to the former and the coefficient 1 to the latter. Finally, taking into account all distributions, their parameters and weights, the expert creates the final probability density function as a weighted sum of separate distributions.

The colored lines on Figure 2.4.4 show the four distributions from the example described: a lognormal distribution with the average price value of x = $55 and volatility of 24% (weight of 3); an exponential distribution corresponding to breaking the lower threshold level of xd = 45 with σd = 5 (weight of 1); an exponential distribution corresponding to breaking the upper threshold level of xu = 60 with σu = 10 (weight of 2); and a uniform distribution reflecting the idea of equal probability for the price to take on any value within the $30-$60 range (weight of 1). The unified distribution shown in Figure 2.4.4 has a complex shape resulting from the combination of different basic distributions.

Figure 2.4.4. Unified probability density function created by combining separate basic distributions.

Consider another example of creating a unified probability density function on the basis of several basic distributions. Suppose that an expert was requested to create a forecast for IBM stock for the September 2008, expiration date. (The date of the forecast is August 29, 2008.) After the fundamental research was accomplished, he decided to use the lognormal and the empirical distributions and selected the following values for their parameters. The expected price of the lognormal distribution was set as equal to the current price, and the variance was derived from 120-day historical volatility. For the empirical distribution the expert selected an 80-day horizon of history. Both distributions were combined with equal weights. The thin lines in Figure 2.4.5 depict probability density functions of the lognormal and empirical distributions, whereas the bold line shows the unified distribution. Note that the final distribution has a concave plateau in its central part. It means that the forecast based on both the lognormal and empirical distributions assigns rather high and similar probabilities to all prices within a relatively broad range of $117-$126.

Figure 2.4.5. Unified probability density function (bold line), created by combining the empirical and the lognormal distributions of IBM stock price.

2.4.4 Criteria Calculation on the Basis of the Unified Probability Density Function
As described in the previous section, an expert obtains the unified density function f(B,x) for price x of underlying asset B by combining several basic distributions (each of which represents a separate scenario forecast for a future date T), selecting their parameters and assigning each of them a weight corresponding to the probability of this particular scenario. The unified function can be used to calculate different criteria in the form of the following integral:

(2.4.1)

If the function P(B,S,x,T) is a payoff function of combination S, the integral I(B,S) will estimate the expected profit on the basis of unified distribution f(B,x). If S is a trivial combination consisting of the only option, this integral will evaluate the fair value of the option. Naturally, the accuracy of this estimate fully depends on the choice of basic distributions, their parameters and weights.

If the value of the function P(B,S,x,T) represents the profit of combination S normalized by margin requirements and time of position holding, then the integral I(B,S) will estimate the expected yield on the basis of unified distribution. Other criteria (like profit probabilities and ratios of expected profit to loss) can be calculated in a similar way (sections 2.1 to 2.3).

2.4.5 Construction and Valuation of Complex Strategies Based on the Unified Probability Density Function

In the context of the systematic approach, we define the option strategy as a specific form of the payoff function corresponding to a specific structure of an option combination. The majority of simple option strategies have unimodal and, in most cases, symmetric payoff functions. Unimodality implies that the payoff function has a single peak or bottom. Combinations corresponding to simple option strategies can be adequately valued by one of the basic probability density functions because all of them are unimodal. For example, payoff functions of such simple strategies as long or short strangle/straddle, long or short calendar spread have one and only one minimum or maximum. Consequently, option combinations belonging to these strategies can be effectively estimated by application of one of the basic density functions.

Unified density functions constructed by combining several basic distributions are usually polymodal with several local maximums. For such functions it is preferable to create complex option strategies with payoff functions that also have several local peaks. The main point here is to superimpose peaks and bottoms of the payoff function with those of the unified density function. The closer the extreme values, the higher the criteria values. The increase in criteria values implies that profit probability of the complex option strategy also increases. One of the main advantages of options in comparison to other financial instruments is the possibility to construct payoff functions of almost any desired shape. We exploit this quality to create complex option strategies with payoff functions matching the unified expert distributions.

Step by step we consider the following example of (1) making an expert forecast, (2) building a unified distribution on its basis, and (3) creating a corresponding complex option strategy.

The expert reckons that the VCLK company may be acquired by Microsoft corporation until the next expiration date, June 16, 2007. On May 23, 2007 this stock was worth $32.63. According to experts’ estimation, the possible acquisition price is around $46. After evaluating the possible acquisition price range, the expert formulates the first scenario in the form of a lognormal distribution with $46 mean and variance corresponding to the width of the price range. The second scenario implies that the acquisition will not take place until expiration. In this case, the expert forecasts a slight decrease in price and describes it by a lognormal distribution with $32 mean and variance derived from historical volatility. Based on the probabilities of each scenario, the expert assigned the weight of 0.1 to the first scenario and the weight of 0.9 to the second one.

After combining two lognormal distributions into the unified probability density function, the expert gets the polymodal function with two local maximums to the right and to the left from the current stock price (Figure 2.4.6).

Figure 2.4.6. Expert probability density function obtained by combining two lognormal distributions and the payoff function of the complex option strategy.

Now the expert has to create such an option combination in which positive areas of its payoff function would correspond to the unified density function peaks and negative areas would be close to the low values of the unified probability density function. Quite a few combinations satisfying this condition can be created.

What combination of this variety has the best performance potential? The answer is obvious: Use the criteria to find out. By applying formula 2.4.1 we can calculate several criteria based on integration of the payoff function over the unified probability density function. As an example we calculate three criteria—expected profit value, profit probability, and the ratio of profit to loss—all on the basis of the density function presented in Figure 2.4.6.

We do not discuss all possible combinations that were rejected due to obviously inferior criteria values. The structure of the three best combinations and their corresponding criteria values are shown in Table 2.4.1. The second combination is the best one according to all the criteria. (Its payoff function for the expiration date is shown in Figure 2.4.6.) Thus, we created a complex option strategy matching the unified expert probability density function. The real profitability of this strategy will fully depend on the quality of the expert forecast.

Table 2.4.1. The Structure and the Criteria Values of Three Option Combinations Created for the Unified Expert Probability Density Function Shown in Figure 2.4.6.

2.5 SPECIFIC (NONUNIVERSAL) CRITERIA
All criteria previously discussed are based on applying different probability distributions of the future underlying asset price. Calculation of their values is based on integrating the payoff function or its derivatives over the probability density function. Such criteria can be used to evaluate and compare any option combinations corresponding to different strategies regardless of their payoff function shapes. According to our classification (Chapter 1), such criteria are referred to as universal ones.

However, the structure of many option strategies allows creation of additional criteria suitable only for them or for a limited number of other closely related strategies. Such criteria are not of the universal nature, because they cannot be used to compare combinations belonging to different strategies and possessing payoff functions with different shapes. Next we consider some of them.

2.5.1 Break-Even Range
The mathematical structure of this criterion is simple. Its basic idea is also rather ordinary and, being nonformalized, is frequently used in evaluating option combinations. This criterion is based on the notion of break-even points, which are defined as underlying asset price values where the payoff function is equal to zero. Option combinations may have one break-even point (bull or bear spread), two points (long and short strangle, straddle, calendar spreads), or a multitude of such points (different complex strategies). The underlying asset itself has the only break-even point that coincides with the price of this asset at the time of position opening.

The idea of this criterion is based on the statement that trading attractiveness of an option combination increases when the underlying asset price range, in which the payoff function is positive, broadens. Because break-even points are the boundaries of this range, it is natural to use them for criteria calculation. The position of the current price in relation to break-even points is also important. If the price is situated between two break-even points at the time of position opening (which is true in most cases), it is not only the range that is important, but the distance between the current price and the nearest break-even point as well. Note that the absolute range value is not so informative. For a stock worth $10, a range of $2 is rather big (because it is 20% of the price); the same range for a stock worth $50 is much narrower (only 4% of the price). Accordingly, criteria values based on the break-even range should be normalized either by the current price of the underlying asset or by another characteristic.

Criterion Calculation Method
The criterion estimating how wide the break-even range is in relation to the current underlying asset price is calculated as

(2.5.1)

where ρ(B,S,X) is the distance between the break-even points of combination S, B is the underlying asset, and X is the current price of the underlying asset.

This version of the criterion does not take into account the position of the current underlying asset price relative to the break-even points. We can fix it by defining ρ(B,S,X) as a distance between the current price and the nearest break-even point.

For the short straddle strategy, high value of this criterion (calculated according to equation 2.5.1) corresponds to the higher potential profitability of a combination. When applying the same criterion to the long strangle strategy, ρ(B,S,X) should be defined as the distance between the current price and the most remote break-even point. In this case, low criterion values indicate higher profitability of the evaluated combination.

Different underlying assets may have different variability values. Therefore, it seems reasonable to apply an additional normalization factor. Then the break-even range criterion is formalized as

(2.5.2)

where V(B) is the underlying asset volatility and ρ(B,S,X) is either the distance between break-even points or the distance between the current price and the nearest break-even point. The product of the current price by volatility (the denominator of equation 2.5.2) characterizes absolute price deviations from the current value. The choice of volatility estimation procedure, and of the optimization algorithm of its main parameter—the horizon of history—is a separate complicated task. (We discussed it in section 2.1.2.) In some cases it is reasonable to use implied volatility as V(B); in other cases one of the numerous variants of historical volatility should be applied.

Criterion Calculation Example
Consider two short straddles created on April 05, 2007, using options on AMZN and ADBE stocks. The AMZN close price was $41.68; bid prices for Call and Put options with strike 40 were $3.2 and $1.35 correspondingly. The close price of ADBE was $42.61; bid prices of its options with strike 42.5 were $1.65 and $1.3 for Call and Put correspondingly. The expiration date of all the options is May 19, 2007. Suppose that each combination consists of one short Call and one short Put option. To evaluate the potential attractiveness of these two combinations, we estimate and compare both variants of the criterion calculated according to formula 2.5.1.

Figure 2.5.1 shows positions of both short straddles relative to their underlying prices. At first glance, the AMZN combination seems to be better than the ADBE combination because its premium is higher. The break-even range of the AMZN combination—$9.10 (44.55 – 35.45)—is also wider than that of the ADBE combination—$5.90 (45.45 – 39.55). The criterion value calculated according to that version of formula 5.2.1, where ρ(B,S,X) is the distance between break-even points, also indicates the advantage of the AMZN straddle (ProfitRange(B,S) = 0.22) over the ADBE straddle (ProfitRange(B,S) = 0.14).

Figure 2.5.1. Payoff functions of two short straddles created using options on AMZN and ADBE stocks. Arrows indicate current stock prices at the time of combination creating.

To obtain a different insight into the comparison of these two combinations, we evaluate the distance from the current price to the nearest break-even point. For the AMZN combination it is 44.55 – 41.68 = $2.87, and for the ADBE combination it is 42.61 – 39.55 = $3.06. The criterion calculated according to the second version of formula 5.2.1 (where ρ(B,S,X) is the distance between the current price and the nearest break-even point) has the following values: AMZN ProfitRange(B,S) = 0.69, ADBE ProfitRange(B,S) = 0.72. It means that, according to the second version of the same criterion, the ADBE combination is preferable (which is contrary to the conclusion based on the first version of the criterion).

What should we do if the same criterion calculated in two different ways gives opposite results? Which of two criterion variants should we rely on when they contradict each other? The following approach can be applied. If we are market-neutral with regard to the underlying asset (that is, we do not forecast the price direction), then the numerator of formula 2.5.1 should express the distance between the current price and the nearest break-even point. Alternatively we may suppose that the probability of certain price direction is higher (which means that we are not market-neutral). In this case we can build the combination in a way that either maximizes or minimizes the distance between the current price and the nearest break-even point (depending on the strategy and the predicted price direction). To evaluate such combinations the numerator of formula 2.5.1 should express the distance between two break-even points.

2.5.2 IV/HV Ratio
One of the ideas of option trading is that opening short positions implies receiving a premium that turns into profit as the time value of options decays. However, profits generated by time decay are accompanied by losses induced by price changes. Strategies like short straddle, short strangle, and those with a similar payoff function profile are good examples vividly illustrating this idea. (Such strategies are usually classified as selling volatility.) For strategies with an inverse payoff function profile (classified as buying volatility), the opposite statement is correct: The profit from price changes is offset by the time decay of the option premium paid for the combination.

Choosing between buying or selling volatility, you should determine which factor—time decay or price change—will prevail. (This is in addition to the forecast of the volatility itself.) To develop a criterion based on the comparison of these two factors, we have to express them numerically.

The possibility of deriving profit from time decay depends, among other things, on the expensiveness of options that may be expressed through the implied volatility (IV). The magnitude of price movements can be characterized by historical volatility of the underlying asset (HV).

Considerable excess of implied volatility IV over historical volatility HV suggests the superiority of selling volatility strategies where short option positions are preferable to long ones. The opposite statement also holds true: Excess of historical volatility over implied volatility suggests the superiority of buying volatility strategies where long option positions dominate over short ones. In the first case options are considered to be overvalued, in the second case—undervalued. These considerations may be formalized to form a criterion expressing the IV/HV ratio:

(2.5.3)

The ratio of two volatilities looks rather ordinary. However, this simplicity hides a multitude of potential variants that may be used to compute this ratio. These variants differ not only in their computation algorithms, but also in selection of parameters used to calculate volatility indicators.

Criterion Parameters
The numerator of equation 2.5.3 contains implied volatility of combination S corresponding to underlying asset B. Implied volatility is a market estimate of the future variability of the underlying asset price, which will be realized from the current time until the expiration date. In other words, implied volatility is a value characterizing option expensiveness expressed through the Black-Scholes formula (or any other model).

The classical definition of implied volatility relates to a single option. IV is derived from the Black-Scholes equation by substituting the current market price of the option into the model’s formula. Because option combinations usually contain several options, it is preferable to use an index of implied volatility combining the implied volatilities of several separate options. The simplest solution is to average the implied volatilities of all options included in the combination. More complicated averages can also be used. Companies specializing in market data delivery offer their versions of implied volatility index for different underlying assets. Their indexes are based on averaging IV corresponding to different options; higher weights are assigned to series that are closer to the current date and to strikes, which are closer to the current price. Precise formulae are considered to be the intellectual property of data vendors and usually are not disclosed. However, such indexes are inappropriate for calculation of the IV/HV criterion because they relate to the underlying asset in general rather than to a combination of specific options. (Here we describe a situation where these indexes can still be applied.)

There are a lot of alternative techniques for assessment of implied volatility. Investment companies usually develop their own methods and do not disclose them. Nevertheless, it is possible to give some general recommendations.

For the comparability of results, all option prices should be fixed simultaneously (that is, should correspond to the same moment in time).
One serious problem giving rise to considerable inaccuracies in estimation of implied volatility is the spread between bid and ask option prices. Which of them should be substituted into the model? Can we use their average? These questions should be answered to obtain the reliable results. A smart approach to solving this problem is to gather statistical data about your own trading and determine the extent to which your execution prices are close to the best market prices existing in the market at the time of execution. Consider the case of options selling (when bid is the best price and ask is the worst price). For each trade we calculate the execution efficiency indicator:
where Price is your real execution price, Bid and Ask are bid and ask prices at the time of trade execution (to be more exact, before the order was placed). Averaging this indicator for all trades executed over a certain time period gives MeanExecutionEfficiency. Using MeanExecutionEfficiency we can estimate the prices (ModelPrice) appropriate for derivation of implied volatility:

(2.5.4)

where Bid and Ask are current bid and ask prices at the time of IV calculation.

When calculating the implied volatility index, we suggest using the previously described weight principle but taking into account only the options that are used in the combination under consideration.
Because option price data vendors often provide inaccurate, lagging, and even false information, it is necessary to develop and regularly apply the monitoring algorithms intended to control the accuracy of incoming data.
Now consider the denominator of equation 2.5.3. The details and peculiarities of historical volatility (HV) calculation were discussed in section 2.1.2. Here we merely repeat the main principles. Historical volatility reflects the past variability of the underlying asset price. In the simplest of cases, HV can be calculated by formula 2.1.2. The length of history N used to calculate HV is an extremely important parameter that strongly influences the results. Owing to statistical nonstationarity of market characteristics, a very low N can give nothing but local information on volatility, whereas a very high N can include events and data that are of little importance today. When calculating the IV/HV ratio, it is optimal to use time periods ranging from 30 to 240 days. In each particular case the precise N value should be determined by the specificity of a given trading strategy.

Criterion Peculiarities

The IV/HV ratio criterion has one peculiarity that the majority of the criteria do not possess. It can be used not only to analyze option combinations but also to compare underlying assets in respect to their suitability for implementation of the whole group of option strategies (selling or buying volatility). High criterion value (when IV exceeds HV) indicates that selling volatility strategies are more appropriate for this underlying asset. On the contrary, low criterion value often indicates that buying volatility is preferable. Such interpretation of criterion values relates to underlying assets themselves rather than to combinations of their options. If the IV/HV ratio is used in this way, the implied volatility should be estimated on the basis of all traded options (assigning higher weights to series that are closer to the current date and to strikes situated closer to the current price). It is even possible to use IV indexes supplied by independent information agencies. However, using “ready-made” indexes makes it impossible to calculate IV values more accurately using formula 2.5.4.

Applying this criterion in selecting a group of strategies—buying or selling volatility—allows us to divide the initial set of underlying assets into two subsets. Each subset corresponds to one or another group. However, the next step requires applying additional criteria intended to select the most suitable underlying assets and specific strategies within each subset. Actually, the same criterion (IV/HV ratio) can be used again for this purpose, but in this case the numerator of equation 2.5.3 should contain another IV, calculated specifically for each combination rather than the universal index value.

Another peculiarity of IV/HV ratio is rather contra-intuitive: Extremely high and low values of this criterion usually indicate the inappropriateness of a combination (or an underlying asset) rather than its superiority. The reason is that extreme values of implied and historical volatility are frequently caused by extraordinary fundamental events, which have just taken place or are anticipated in the nearest future.

When IV exceeds its average value, it usually creates opportunities to realize option strategies based on volatility selling. However, an abnormally high IV may arise from unique temporary circumstances, which are not suitable for implementation of standard option strategies. Extremely high IV usually means that the market anticipates news concerning some essential event such as a court decision, M&A announcement, new products launch, and so on. The exact event date, its probability, and sometimes even the essence itself are often unknown to the public. But if such an event occurs, it frequently causes a considerable price move. Sometimes the essence of the event and its date are predefined and known to the wider public (such as publication of accounting information with fixed terms and periodicity). A classic example is a quarterly earnings release. It can also be publication of important industry or macroeconomic statistical data. Such events often induce sharp changes in underlying asset prices or IV values. In these cases it is useless to predict future price variability on the basis of historical volatility because the price movement caused by the news can be several times greater than past price fluctuations. Such situations are extremely risky for standard selling volatility strategies, and they should either be avoided or combined with forecasts based on creation of expert probability distributions.

The opposite situation of abnormally low IV values usually takes place after the announcement of the acquisition. When this fact becomes known, the stock price sharply jumps up to the acquisition price level (thereby raising the historical volatility), and the option price plunges (thereby decreasing the implied volatility). Afterward the stock price will not change in the near future. (It will fluctuate within a narrow range around the acquisition price.) In this situation some buying volatility strategies may look very attractive, having no prospects at all (because there will be no considerable price and volatility changes).

2.5.3 Relative Frequency Criterion
The idea of this criterion (and of the previous one and all the other criteria intended to evaluate option combinations) is based on the divergence between the premium (expressed by IV or otherwise) and the variability of the underlying asset price (expressed by HV or otherwise). The main distinction of this criterion is that instead of analyzing the absolute divergence between these characteristics (expressed by their ratio or otherwise), it estimates the relative frequency of their occurrence.

Implied volatility IV(S,B,t) of combination S built for underlying asset B at the moment in time t will be used as a characteristic of the option expensiveness. Methods of IV(S,B,t) calculation were described previously. For this criterion we suggest using simple averaging of implied volatilities of all options composing the combination. To compute IV of each separate option, we substitute its market prices adjusted according to formula 2.5.4 into the Black-Scholes model. Because implied volatility sharply increases as the expiration date approaches, the options with an expiration date that is less than 5 trading days away should be discarded from the averaging procedure.

The underlying asset price variability will be expressed as the absolute value of the logarithm of daily price changes. The following notations will be used: C(t) is the underlying asset close price at the moment in time t; L is the length of history horizon; and T0 is the current moment in time. We calculate price changes according to the equation image at the time interval Ω = {T0 – L, T0 – L + 1,...,T0}.

As a result, we obtain L pairs of IV(S,B,t) and p(B,t) values. The criterion is defined as the relative frequency of days on the given horizon of history, when implied volatility of the combination was higher than the real price change:

(2.5.5)

Here the symbol |{...}| denotes the number of elements in the set. There are several variants of this criterion. Firstly, we can use 2-day, 3-day, and such price changes instead of 1-day changes. (The period length is one of the parameters to be optimized.) Secondly, we can define the threshold value for the difference between IV(S,B,t) and p(B,t) (another parameter). Thirdly, the frequency of this excess can be expressed in different ways. The simple way was used in formula 2.5.5; the advanced variant would be to build a complete frequency distribution of the differences between IV(S,B,t) and p(B,t). Finally, we can create several versions of this criterion changing the method of determining the length of the history horizon. (The importance and the extent to which L influences the criterion value were discussed in the section devoted to empirical distribution.)

The disadvantage of the relative frequency criterion consists in its inappropriateness to evaluate combinations containing deep in-the-money and out-of-the-money options. (They are usually illiquid or have negligible volumes.) Due to the volatility smile phenomenon, such options may have extremely high (or low) IV values. In these cases, whatever the price change is, IV would be higher (lower) than the corresponding price move. Therefore, this criterion can only be used to compare combinations consisting of at-the-money options.

The interpretation of this criterion is straightforward. High FrIV(B) values indicate that options are overvalued relative to the underlying asset price variability potential. Thus, when selecting combinations containing more short options than long ones (strategies of selling volatility), the variants with higher criterion values should be preferred. Low criterion values indicate that the underlying asset price variability is underestimated (not fully reflected in the current option prices). Therefore, when selecting combinations containing mainly long options (buying volatility strategies), the alternatives with lower criterion values should be preferred.

2.5.4 The Ratio of Normalized Time Value to the Coefficient of Absolute Price Changes Distribution
The structure of this criterion is similar to that of the IV/HV ratio criterion. It is the ratio with the option expensiveness indicator in the numerator and the underlying asset price variability indicator in the denominator. The difference is that both indicators are based on fundamentally different principles without using historical and implied volatilities. This allows avoiding inaccuracies and assumptions related to these indicators. Like the IV/HV ratio this criterion can be used not only for comparing option combinations but also for selecting the underlying assets appropriate for strategies of buying or selling volatility. High criterion values indicate that selling volatility is preferable for the particular underlying asset and vice versa. The criterion can also be used to compare option combinations, but with one important restriction: Only combinations with identical structure are comparable. It means that the “ratio of normalized time value to the coefficient of absolute price changes distribution” is a specific (nonuniversal) criterion. (The reason for this lies in the numerator calculation method and will become clear later.)

We begin with the numerator that shows how expensive the options are at the current moment in time. First, we express the time value of the combination as a fraction of the underlying asset price. To make underlying assets comparable by this criterion, two conditions have to be met. Firstly, all combinations must have an identical structure. To be more precise, they must be straddles with the strike that is closest to the current underlying asset price. (Strangles can also be used; we discuss it next.) Secondly, for all combinations the price of the underlying asset must be exactly equal to the corresponding strike price. (Then the option premium will consist only of time value.) Although the first condition is easy to fulfill (it depends only on our own choice), the second one is an idealization that can never be realized in real life for a number of assets simultaneously. Nevertheless, we can approximate this idealization by calculating what would be the value of options if the underlying asset price has changed abruptly and coincided with the nearest strike. It can be done by application of the option’s delta, which shows by how many points the option price will change if the underlying asset price changes by one point. To reduce real prices of the Put option (Pp) and the Call option (Pc) to hypothetical prices (Pp’ and Pc’), which would have been formed if the current underlying asset price (X) coincided with the nearest strike (S), the following transformations need to be executed:

(2.5.6)

where Δc and Δp are Call and Put option deltas.

The next step is to normalize the time value of the combination by the underlying asset price (which is equal to S after transformation 2.5.6):

(2.5.7)

To obtain the same indicator for strangles, you should take into account an important peculiarity. Consider the following unified strangle structure: The combination is formed of Put and Call options with the nearest to the current price (X) out-of-the-money strikes(Sp and Sc correspondingly). The option premium of the combination having such structure consists only of time value. The peculiarity mentioned is that distances between adjacent strikes expressed as percentage of the current price X are different for different underlying assets. This implies that, all other terms being equal, the combination relating to the stock with lower (Sc – Sp)/X value will have a higher time value. This is quite natural because strikes of both options of such stock are situated “closer to the money.” To eliminate this effect and make all strangles comparable by their time value, we normalize time value by the strike step: (Pp + Pc) / (Sc – Sp). This expression should be further normalized by the current price of the underlying asset to obtain the indicator for strangles similar to the one developed for straddles (equation 2.5.7):

(2.5.8)

Note that normalizing time value by (Sc – Sp) does not fully solve the problem of underlying assets comparability. As the current price moves away from the strike, time value decreases nonlinearly. Consequently, cheaper underlying assets (those with more infrequent strikes expressed as a percentage of the price) will have overpriced time value compared to more expensive underlying assets. Thus we suggest using formula 2.5.8 to compare only underlying assets with the price difference of no more than 20% to 25%.

Expressions 2.5.7 and 2.5.8 allowing comparison between different underlying assets by time value of their options serve as the numerator of the criterion. It is important to note that indicators calculated by application of equation 2.5.7 are incomparable with those obtained with equation 2.5.8 because time value of the straddle is always higher than that of the strangle. Besides, these indicators express different values. The first one expresses time value as a percentage of the underlying asset price. The second one expresses time value (also as a percentage of the underlying asset price) accounting for each dollar of the distance between strikes.

The idea of the indicator serving as the criterion’s denominator consists in expressing the underlying asset price variability without resorting to historical volatility or variance. This can be solved in various ways; here we discuss only one of them. Putting aside price trends, we express its variability by application of the exponential function to analyze the absolute price changes.

We fix the horizon of history L, relative to the current point in time T0. For each underlying asset b at the time interval Ω = {T0 – L,T0 – L + 1,...,T0} we obtain the set of L absolute values of daily price changes: image. This set is then ranked in ascending order of {ρ(B, ti): ρ(B, ti) ≤ ρ(B, ti+1)} values and the cumulative empirical distribution function is constructed on the basis of this ordering:

Applying the least-squares method we approximate the function F(B,x) with the exponential distribution function image. For every underlying asset B we obtain its λ(B) value. The probability density function of the exponential distribution is image. If two different stocks B1 and B2 have different values of the coefficient λ(B) and λ(B1) > λ(B2), then stock B1 has fewer small price changes while big price fluctuations are more frequent. That is, the distribution of price changes of the stock B1 has fatter “tails.” Such a property indicates that the price of the first underlying asset is more variable than the price of the second one.

Evaluating the ratio of TimeValue calculated by application of equation 2.5.7 (or 2.5.8) to λ(B), we obtain the value of the criterion called “ratio of normalized time value to the coefficient of absolute price changes distribution.”

Finally, we would like to emphasize that this criterion and the IV/HV ratio can be used to create additional hybrid criteria. For example, we can divide IV by λ(B) or, on the contrary, calculate ratio of TimeValue to HV.
